{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MichaelBillan/Cloud-Computing/blob/main/cloud-homeworks/cloud-hw3/HW3_PANTHER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEiyoRSnWms0",
        "outputId": "3ed57f77-9d5d-48b4-db2c-d995e8f37329"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/google/colab/_import_hooks/_hook_injector.py:55: FutureWarning: \n",
            "\n",
            "All support for the `google.generativeai` package has ended. It will no longer be receiving \n",
            "updates or bug fixes. Please switch to the `google.genai` package as soon as possible.\n",
            "See README for more details:\n",
            "\n",
            "https://github.com/google-gemini/deprecated-generative-ai-python/blob/main/README.md\n",
            "\n",
            "  loader.exec_module(module)\n"
          ]
        }
      ],
      "source": [
        "# ================================================\n",
        "# PART 1: INSTALL, IMPORTS & SETTINGS (OPTIMIZED)\n",
        "# ================================================\n",
        "\n",
        "# --------- 0) Fast, safe installs: install ONLY if missing ----------\n",
        "import sys, importlib.util, subprocess\n",
        "\n",
        "def pip_install_if_missing(packages):\n",
        "    \"\"\"\n",
        "    Install packages only if their importable module is missing.\n",
        "    Note: module name is inferred from package name (works for most common packages).\n",
        "    \"\"\"\n",
        "    missing = []\n",
        "    for pkg in packages:\n",
        "        base = pkg.split(\"==\")[0].split(\">=\")[0].split(\"[\")[0]\n",
        "        module = {\n",
        "            \"google-api-python-client\": \"googleapiclient\",\n",
        "            \"google-generativeai\": \"google.generativeai\",\n",
        "        }.get(base, base.replace(\"-\", \"_\"))\n",
        "        if importlib.util.find_spec(module) is None:\n",
        "            missing.append(pkg)\n",
        "\n",
        "    if missing:\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", *missing])\n",
        "\n",
        "# Base features (UI, Drive, Gemini, NLTK, PDF)\n",
        "pip_install_if_missing([\n",
        "    \"gradio\",\n",
        "    \"nltk\",\n",
        "    \"fpdf\",\n",
        "    \"google-generativeai\",\n",
        "    \"google-api-python-client\",\n",
        "    \"firebase-admin\",\n",
        "    \"pyspark\",\n",
        "])\n",
        "\n",
        "# --------- 1) Imports (only what we actually use) ----------\n",
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from requests import get as http_get  # fixed: we use http_get(...)\n",
        "from os import environ\n",
        "from collections import defaultdict\n",
        "\n",
        "from google.colab import auth\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "import google.generativeai as genai\n",
        "from fpdf import FPDF\n",
        "from PIL import Image as PILImage\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "\n",
        "# --------- 2) Configuration ----------\n",
        "# SECURITY NOTE: Avoid hardcoding API keys in notebooks you share.\n",
        "# Prefer: environ[\"GEMINI_API_KEY\"] = \"...\" in Colab Secrets or runtime env.\n",
        "environ[\"GEMINI_API_KEY\"] = \"AIzaSyDhE_AVpHoRINEEfGY35v4xkOuborR81YM\"\n",
        "GEMINI_API_KEY = environ[\"GEMINI_API_KEY\"]\n",
        "\n",
        "FOLDER_ID = '1BWa5Hy-4aTifH0zHULoPMwi9qL-s_5-l'\n",
        "BASE_URL = \"https://server-cloud-v645.onrender.com/\"\n",
        "MODEL_ID = \"linkanjarad/mobilenet_v2_1.0_224-plant-disease-identification\"\n",
        "\n",
        "# --------- 3) NLTK downloads only if missing ----------\n",
        "def nltk_download_if_missing(resource_path, download_name=None):\n",
        "    try:\n",
        "        nltk.data.find(resource_path)\n",
        "    except LookupError:\n",
        "        nltk.download(download_name or resource_path.split(\"/\")[-1], quiet=True)\n",
        "\n",
        "nltk_download_if_missing(\"corpora/stopwords\", \"stopwords\")\n",
        "nltk_download_if_missing(\"tokenizers/punkt\", \"punkt\")\n",
        "\n",
        "# --------- 4) Globals ----------\n",
        "GLOBAL_CACHE = {\"temperature\": None, \"humidity\": None, \"soil\": None}\n",
        "DOC_TITLES = {}\n",
        "ARTICLES = {}\n",
        "drive_service = None\n",
        "engine = None\n",
        "ACTIVE_MODEL = \"models/gemini-pro\"\n",
        "\n",
        "# Lazy model (vision) ‚Äî loaded only when first used\n",
        "plant_classifier = None\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "eLxQJj6aW7MR"
      },
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# PART 2: HELPER FUNCTIONS & CLASSES\n",
        "# ==========================================\n",
        "\n",
        "IL_TZ = pytz.timezone('Asia/Jerusalem')\n",
        "\n",
        "# --- 1. Drive & File Helpers ---\n",
        "def get_files_from_folder(folder_id):\n",
        "    try:\n",
        "        results = drive_service.files().list(\n",
        "            q=f\"'{folder_id}' in parents and mimeType='application/vnd.google-apps.document' and trashed=false\",\n",
        "            fields=\"files(id, name)\", pageSize=20\n",
        "        ).execute()\n",
        "        return results.get('files', [])\n",
        "    except:\n",
        "        return []\n",
        "\n",
        "def fetch_gdoc_content(file_id):\n",
        "    try:\n",
        "        content = drive_service.files().export_media(fileId=file_id, mimeType='text/plain').execute()\n",
        "        return content.decode('utf-8')\n",
        "    except:\n",
        "        return \"\"\n",
        "\n",
        "\n",
        "# --- 2. Search Engine Logic (Class) ---\n",
        "class LectureSearchEngine:\n",
        "    def __init__(self):\n",
        "        self.word_locations = defaultdict(list)\n",
        "        self.documents = {}\n",
        "        self.titles = {}\n",
        "        self.stop_words = set(stopwords.words('english'))\n",
        "        self.stop_words.update({'a', 'an', 'the', 'and', 'or', 'in', 'on', 'at', 'to', 'for', 'of', 'with'})\n",
        "\n",
        "    def build_index(self, docs, titles):\n",
        "        self.documents = docs\n",
        "        self.titles = titles\n",
        "        self.word_locations.clear()\n",
        "\n",
        "        for doc_id, content in self.documents.items():\n",
        "            words = re.findall(r'\\w+', content.lower())\n",
        "            word_counts = defaultdict(int)\n",
        "\n",
        "            for word in words:\n",
        "                if word not in self.stop_words:\n",
        "                    word_counts[word] += 1\n",
        "\n",
        "            for word, count in word_counts.items():\n",
        "                self.word_locations[word].append((doc_id, count))\n",
        "\n",
        "    def get_context(self, content, query_words, window=150):\n",
        "        content_lower = content.lower()\n",
        "        best_idx = -1\n",
        "        for word in query_words:\n",
        "            idx = content_lower.find(word)\n",
        "            if idx != -1:\n",
        "                best_idx = idx\n",
        "                break\n",
        "\n",
        "        if best_idx != -1:\n",
        "            start = max(0, best_idx - 50)\n",
        "            end = min(len(content), best_idx + window)\n",
        "            return \"...\" + content[start:end].replace(\"\\n\", \" \") + \"...\"\n",
        "        return content[:200].replace(\"\\n\", \" \") + \"...\"\n",
        "\n",
        "    def search(self, query, num_results=3):\n",
        "        query_words = [w.lower() for w in re.findall(r'\\w+', query) if w.lower() not in self.stop_words]\n",
        "        if not query_words:\n",
        "            return []\n",
        "\n",
        "        page_scores = defaultdict(lambda: {'matches': 0, 'total_freq': 0})\n",
        "        for word in query_words:\n",
        "            for doc_id, freq in self.word_locations.get(word, []):\n",
        "                page_scores[doc_id]['matches'] += 1\n",
        "                page_scores[doc_id]['total_freq'] += freq\n",
        "\n",
        "        ranked = [(doc_id, s['matches'], s['total_freq']) for doc_id, s in page_scores.items()]\n",
        "        ranked.sort(key=lambda x: (x[1], x[2]), reverse=True)\n",
        "\n",
        "        results = []\n",
        "        for doc_id, matches, total_freq in ranked[:num_results]:\n",
        "            title = self.titles.get(doc_id, \"Unknown\")\n",
        "            content = self.documents.get(doc_id, \"\")\n",
        "            context = self.get_context(content, query_words)\n",
        "            results.append({\n",
        "                'title': title,\n",
        "                'score': f\"Matches: {matches}, Freq: {total_freq}\",\n",
        "                'context': context\n",
        "            })\n",
        "        return results\n",
        "\n",
        "\n",
        "# --- 3. Gemini & RAG Helpers ---\n",
        "def get_working_model():\n",
        "    genai.configure(api_key=GEMINI_API_KEY)\n",
        "    # NEW CODE: Force use of gemini-2.5-flash as requested\n",
        "    return \"models/gemini-2.5-flash\"\n",
        "\n",
        "    # OLD CODE: return \"models/gemini-1.5-flash\"\n",
        "\n",
        "def search_engine_rag(query):\n",
        "    if not ARTICLES:\n",
        "        return \"‚ö†Ô∏è Error: No documents loaded.\"\n",
        "    results = engine.search(query)\n",
        "    if not results:\n",
        "        return f\"No results found for: '{query}'\"\n",
        "\n",
        "    output_log = f\"üîé Found {len(results)} docs (Ranked by Matches & Freq)\\n\" + \"=\" * 40 + \"\\n\"\n",
        "    context_text = []\n",
        "\n",
        "    for res in results:\n",
        "        output_log += f\"\\nüìÑ [{res['title']}] ({res['score']})\\n - {res['context']}\\n\"\n",
        "        context_text.append(f\"Source ({res['title']}): {res['context']}\")\n",
        "\n",
        "    try:\n",
        "        # NEW CODE: Explicitly use 2.5 flash\n",
        "        model = genai.GenerativeModel(\"models/gemini-2.5-flash\")\n",
        "        # OLD CODE: model = genai.GenerativeModel(\"models/gemini-1.5-flash\")\n",
        "\n",
        "        prompt = (\n",
        "            f\"Question: {query}\\n\"\n",
        "            f\"Base your answer ONLY on the following context:\\n\" + \"\\n\".join(context_text)\n",
        "        )\n",
        "        response = model.generate_content(prompt)\n",
        "        gemini_summary = f\"\\nü§ñ AI Answer:\\n{response.text}\\n\"\n",
        "    except Exception as e:\n",
        "        gemini_summary = f\"\\n(AI Error: {e})\\n\"\n",
        "\n",
        "    return gemini_summary + \"\\n\" + output_log\n",
        "\n",
        "def get_index_table():\n",
        "    data = []\n",
        "    if engine:\n",
        "        for i, (word, locs) in enumerate(engine.word_locations.items()):\n",
        "            if i >= 100:\n",
        "                break\n",
        "            data.append({\"term\": word, \"docs\": str(locs)})\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "\n",
        "# --- 4. IoT Helpers ---\n",
        "def fetch_data_as_df(feed, limit, save_to_firebase=True):\n",
        "    try:\n",
        "        resp = http_get(f\"{BASE_URL}/history\", params={\"feed\": feed, \"limit\": limit}, timeout=3)\n",
        "        data = resp.json()\n",
        "        if \"data\" in data and len(data[\"data\"]) > 0:\n",
        "            df = pd.DataFrame(data[\"data\"])\n",
        "\n",
        "            # --- TIMEZONE FIX START ---\n",
        "            # 1. Convert string to datetime objects\n",
        "            df[\"created_at\"] = pd.to_datetime(df[\"created_at\"])\n",
        "\n",
        "            # 2. Localize to UTC if naive (API usually sends UTC)\n",
        "            if df[\"created_at\"].dt.tz is None:\n",
        "                df[\"created_at\"] = df[\"created_at\"].dt.tz_localize('UTC')\n",
        "\n",
        "            # 3. Convert to Israel Time\n",
        "            df[\"created_at\"] = df[\"created_at\"].dt.tz_convert(IL_TZ)\n",
        "\n",
        "            # 4. Remove timezone info (make it naive-local) for cleaner plotting/PDF\n",
        "            df[\"created_at\"] = df[\"created_at\"].dt.tz_localize(None)\n",
        "            # --- TIMEZONE FIX END ---\n",
        "\n",
        "            df[\"value\"] = pd.to_numeric(df[\"value\"], errors=\"coerce\")\n",
        "            df = df.sort_values(\"created_at\")\n",
        "            GLOBAL_CACHE[feed] = df\n",
        "\n",
        "            if save_to_firebase:\n",
        "              try:\n",
        "                msg = save_iot_df_to_firebase(feed, df)\n",
        "                print(msg)\n",
        "              except Exception as e:\n",
        "                print(f\"Error saving to Firebase: {e}\")\n",
        "\n",
        "            return df\n",
        "    except:\n",
        "        return None\n",
        "    return None\n",
        "\n",
        "\n",
        "def create_plot(df, title, color):\n",
        "    if df is None or df.empty:\n",
        "        return None\n",
        "    fig, ax = plt.subplots(figsize=(8, 3.5))\n",
        "    ax.plot(df[\"created_at\"], df[\"value\"], marker='.', linestyle='-', color=color, linewidth=1.5)\n",
        "    ax.set_title(title)\n",
        "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "LEADERBOARD_DATA = [\n",
        "    {\"Player\": \"Foaad\", \"Score\": 255},\n",
        "    {\"Player\": \"You ü´µ\", \"Score\": 245},\n",
        "    {\"Player\": \"Michael\", \"Score\": 90},\n",
        "    {\"Player\": \"Yazan\", \"Score\": 75},\n",
        "    {\"Player\": \"Baraah\", \"Score\": 60},\n",
        "    {\"Player\": \"Rami\", \"Score\": 15}\n",
        "]\n",
        "\n",
        "def get_leaderboard_df():\n",
        "    df = pd.DataFrame(LEADERBOARD_DATA)\n",
        "    df = df.sort_values(by=\"Score\", ascending=False).reset_index(drop=True)\n",
        "    df.insert(0, 'Rank', range(1, 1 + len(df)))\n",
        "    return df\n",
        "\n",
        "def update_leaderboard():\n",
        "    global LEADERBOARD_DATA\n",
        "    for player in LEADERBOARD_DATA:\n",
        "        if \"You\" in player[\"Player\"]:\n",
        "            player[\"Score\"] += 5\n",
        "            break\n",
        "    return get_leaderboard_df()\n",
        "\n",
        "# --- OPTIMIZED PARALLEL FETCH (LIMIT=1) ---\n",
        "def fetch_sensor_values(ignored_limit):\n",
        "    \"\"\"\n",
        "    Fetches ONLY the latest value (limit=1) for all sensors in PARALLEL.\n",
        "    \"\"\"\n",
        "    val_temp, val_hum, val_soil = \"Loading...\", \"Loading...\", \"Loading...\"\n",
        "    REAL_TIME_LIMIT = 1\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=3) as executor:\n",
        "        future_t = executor.submit(fetch_data_as_df, \"temperature\", REAL_TIME_LIMIT)\n",
        "        future_h = executor.submit(fetch_data_as_df, \"humidity\", REAL_TIME_LIMIT)\n",
        "        future_s = executor.submit(fetch_data_as_df, \"soil\", REAL_TIME_LIMIT)\n",
        "\n",
        "        df_t = future_t.result()\n",
        "        df_h = future_h.result()\n",
        "        df_s = future_s.result()\n",
        "\n",
        "    if df_t is not None and not df_t.empty:\n",
        "        val_temp = f\"{df_t.iloc[-1]['value']} ¬∞C\"\n",
        "    else:\n",
        "        val_temp = \"---\"\n",
        "\n",
        "    if df_h is not None and not df_h.empty:\n",
        "        val_hum = f\"{df_h.iloc[-1]['value']} %\"\n",
        "    else:\n",
        "        val_hum = \"---\"\n",
        "\n",
        "    if df_s is not None and not df_s.empty:\n",
        "        val_soil = str(df_s.iloc[-1]['value'])\n",
        "    else:\n",
        "        val_soil = \"---\"\n",
        "\n",
        "    # --- TIMEZONE FIX: Real-time clock in Israel Time ---\n",
        "    current_time = datetime.now(IL_TZ).strftime(\"%H:%M:%S\")\n",
        "    update_msg = f\"‚è±Ô∏è Last Updated (IL): {current_time}\"\n",
        "\n",
        "    return val_temp, val_hum, val_soil, update_msg\n",
        "\n",
        "def export_json_data(limit):\n",
        "    export_data = {}\n",
        "    feeds = [\"temperature\", \"humidity\", \"soil\"]\n",
        "\n",
        "    for feed in feeds:\n",
        "        df = fetch_data_as_df(feed, limit)\n",
        "        if df is not None and not df.empty:\n",
        "            # Pandas default to_dict handles datetime well, but for JSON dump we might need string conversion\n",
        "            # Since we made them naive-local in fetch_data_as_df, they will export as local time strings.\n",
        "            export_data[feed] = df.to_dict(orient=\"records\")\n",
        "\n",
        "    json_filename = \"iot_data.json\"\n",
        "    try:\n",
        "        with open(json_filename, 'w') as f:\n",
        "            json.dump(export_data, f, default=str)\n",
        "        return gr.File(value=json_filename, visible=True)\n",
        "    except Exception as e:\n",
        "        return gr.File(visible=False)\n",
        "\n",
        "def refresh_dashboard_real():\n",
        "    limit = 20\n",
        "    df_t = fetch_data_as_df(\"temperature\", limit)\n",
        "    df_h = fetch_data_as_df(\"humidity\", limit)\n",
        "    df_s = fetch_data_as_df(\"soil\", limit)\n",
        "\n",
        "    fig_t = create_plot(df_t, \"Temp Trend\", \"#ff6b6b\")\n",
        "    fig_h = create_plot(df_h, \"Hum Trend\", \"#4ecdc4\")\n",
        "    fig_s = create_plot(df_s, \"Soil Trend\", \"#8d6e63\")\n",
        "\n",
        "    val_t = df_t.iloc[-1][\"value\"] if df_t is not None and not df_t.empty else 0\n",
        "    val_h = df_h.iloc[-1][\"value\"] if df_h is not None and not df_h.empty else 0\n",
        "    val_s = df_s.iloc[-1][\"value\"] if df_s is not None and not df_s.empty else 0\n",
        "\n",
        "    status = \"Warning ‚ö†Ô∏è\" if val_t > 35 else \"OK ‚úÖ\"\n",
        "    return fig_t, fig_h, fig_s, f\"{val_t} ¬∞C\", f\"{val_h} %\", f\"{val_s}\", status\n",
        "\n",
        "\n",
        "\n",
        "# --- 5. Image AI Helpers (LAZY LOAD transformers + model) ---\n",
        "def get_plant_classifier():\n",
        "    \"\"\"\n",
        "    Lazily installs/imports transformers and loads the HF model only when first needed.\n",
        "    This avoids slow startup time for users who don't use the Image tab.\n",
        "    \"\"\"\n",
        "    global plant_classifier\n",
        "    if plant_classifier is not None:\n",
        "        return plant_classifier\n",
        "\n",
        "    # Install transformers only if missing (do NOT force torch reinstall)\n",
        "    pip_install_if_missing([\"transformers\"])\n",
        "\n",
        "    from transformers import pipeline\n",
        "    plant_classifier = pipeline(\"image-classification\", model=MODEL_ID)\n",
        "    return plant_classifier\n",
        "\n",
        "def analyze_image(img):\n",
        "    if img is None:\n",
        "        return \"‚ö†Ô∏è Please upload an image.\"\n",
        "    try:\n",
        "        clf = get_plant_classifier()\n",
        "        raw_image = PILImage.fromarray(img.astype('uint8'), 'RGB')\n",
        "        results = clf(raw_image)\n",
        "        top_result = results[0]\n",
        "        label = top_result['label']\n",
        "        score = top_result['score']\n",
        "\n",
        "        if \"healthy\" in label.lower():\n",
        "            return f\"‚úÖ Healthy ({label})\\nConfidence: {score:.1%}\"\n",
        "        return f\"‚ö†Ô∏è Potential Issue: {label.replace('_', ' ').title()}\\nConfidence: {score:.1%}\"\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Error: {str(e)}\"\n",
        "\n",
        "\n",
        "# --- 6. PDF Report Helpers (UPDATED FOR BIG DATA/FIREBASE) ---\n",
        "class PDFReport(FPDF):\n",
        "    def header(self):\n",
        "        self.set_font('Arial', 'B', 15)\n",
        "        self.cell(0, 10, 'IoT Big Data Analytics Report', 0, 1, 'C') # Changed Title\n",
        "        self.ln(5)\n",
        "\n",
        "    def chapter_title(self, title):\n",
        "        self.set_font('Arial', 'B', 12)\n",
        "        self.set_fill_color(200, 220, 255)\n",
        "        self.cell(0, 10, title, 0, 1, 'L', 1)\n",
        "        self.ln(4)\n",
        "\n",
        "    # NEW: Function to display Analytics Table in PDF\n",
        "    def chapter_analytics_table(self, df):\n",
        "        self.set_font('Arial', 'B', 10)\n",
        "        # Table Headers\n",
        "        self.cell(40, 8, 'Feed', 1)\n",
        "        self.cell(30, 8, 'Min', 1)\n",
        "        self.cell(30, 8, 'Max', 1)\n",
        "        self.cell(30, 8, 'Avg', 1)\n",
        "        self.cell(40, 8, 'Anomalies (3s)', 1)\n",
        "        self.ln()\n",
        "\n",
        "        self.set_font('Arial', '', 10)\n",
        "        if df is not None and not df.empty:\n",
        "            for _, row in df.iterrows():\n",
        "                feed_name = str(row.get('feed', 'N/A'))\n",
        "                val_min = f\"{float(row.get('min', 0)):.2f}\"\n",
        "                val_max = f\"{float(row.get('max', 0)):.2f}\"\n",
        "                val_avg = f\"{float(row.get('avg', 0)):.2f}\"\n",
        "                val_anom = str(row.get('anomalyCount_3sigma', 0))\n",
        "\n",
        "                self.cell(40, 8, feed_name, 1)\n",
        "                self.cell(30, 8, val_min, 1)\n",
        "                self.cell(30, 8, val_max, 1)\n",
        "                self.cell(30, 8, val_avg, 1)\n",
        "                self.cell(40, 8, val_anom, 1)\n",
        "                self.ln()\n",
        "        else:\n",
        "             self.cell(0, 8, \"No Analytics Data Available from Firebase\", 1, 1)\n",
        "        self.ln(10)\n",
        "\n",
        "    # (Previous chapter_body commented out / kept as fallback if needed)\n",
        "    def chapter_body_raw(self, df):\n",
        "        self.set_font('Arial', '', 10)\n",
        "        self.cell(90, 8, 'Timestamp', 1)\n",
        "        self.cell(40, 8, 'Value', 1)\n",
        "        self.ln()\n",
        "        if df is not None and not df.empty:\n",
        "            for _, row in df.sort_values(\"created_at\", ascending=False).head(20).iterrows():\n",
        "                self.cell(90, 8, str(row['created_at']), 1)\n",
        "                self.cell(40, 8, str(row['value']), 1)\n",
        "                self.ln()\n",
        "        self.ln(10)\n",
        "\n",
        "# NEW: Updated PDF Generation Function\n",
        "def generate_pdf_report():\n",
        "    # NEW CODE: Fetch Analytics directly from Firebase\n",
        "    df_analytics = load_latest_analytics_from_firebase()\n",
        "\n",
        "    pdf = PDFReport()\n",
        "    pdf.add_page()\n",
        "\n",
        "    # Section 1: Big Data Overview\n",
        "    pdf.chapter_title(\"Big Data Analytics Overview (from Firebase)\")\n",
        "    pdf.chapter_analytics_table(df_analytics)\n",
        "\n",
        "    # Section 2: Raw Snippets (Optional - keeping simplified version)\n",
        "    pdf.chapter_title(\"Recent Raw Data Snippets\")\n",
        "    for feed in [\"temperature\", \"humidity\", \"soil\"]:\n",
        "        # Try to get from cache or fetch small amount\n",
        "        df = GLOBAL_CACHE.get(feed)\n",
        "        if df is None:\n",
        "             df = fetch_data_as_df(feed, 10, save_to_firebase=False) # Don't save to FB again just for report\n",
        "\n",
        "        pdf.set_font('Arial', 'B', 10)\n",
        "        pdf.cell(0, 10, f\"Feed: {feed}\", 0, 1)\n",
        "        pdf.chapter_body_raw(df)\n",
        "\n",
        "    filename = \"iot_bigdata_report.pdf\"\n",
        "    pdf.output(filename)\n",
        "    return filename, f\"‚úÖ Professional Report (Firebase Data) Saved to {filename}\"\n",
        "\n",
        "\n",
        "# --- 7. Firebase Realtime DB Helpers ---\n",
        "import firebase_admin\n",
        "from firebase_admin import credentials, db as firebase_db\n",
        "from datetime import datetime\n",
        "\n",
        "FIREBASE_APP = None\n",
        "FIREBASE_DB_URL = None  # set this from your Firebase console\n",
        "\n",
        "def firebase_init(db_url: str, service_account_path: str = \"/content/serviceAccountKey.json\"):\n",
        "    \"\"\"\n",
        "    Initialize Firebase Admin SDK for Realtime Database.\n",
        "    - db_url example: \"https://<PROJECT_ID>-default-rtdb.europe-west1.firebasedatabase.app/\"\n",
        "    - service_account_path: uploaded JSON in Colab\n",
        "    \"\"\"\n",
        "    global FIREBASE_APP, FIREBASE_DB_URL\n",
        "\n",
        "    FIREBASE_DB_URL = db_url\n",
        "\n",
        "    if not firebase_admin._apps:\n",
        "        cred = credentials.Certificate(service_account_path)\n",
        "        FIREBASE_APP = firebase_admin.initialize_app(cred, {\"databaseURL\": db_url})\n",
        "    else:\n",
        "        FIREBASE_APP = firebase_admin.get_app()\n",
        "\n",
        "    return True\n",
        "\n",
        "def fb_set(path: str, value):\n",
        "    ref = firebase_db.reference(path)\n",
        "    ref.set(value)\n",
        "\n",
        "def fb_push(path: str, value):\n",
        "    ref = firebase_db.reference(path)\n",
        "    ref.push(value)\n",
        "\n",
        "def fb_get(path: str):\n",
        "    ref = firebase_db.reference(path)\n",
        "    return ref.get()\n",
        "\n",
        "def save_index_to_firebase(engine: LectureSearchEngine):\n",
        "    if engine is None or not engine.documents:\n",
        "        return \"‚ö†Ô∏è No index to save.\"\n",
        "\n",
        "    index_payload = {}\n",
        "\n",
        "    for term, locs in engine.word_locations.items():\n",
        "        # IMPORTANT: dictionary, not list\n",
        "        index_payload[term] = {\n",
        "            str(doc_id): int(freq)\n",
        "            for doc_id, freq in locs\n",
        "        }\n",
        "\n",
        "    meta = {\n",
        "        \"createdAt\": datetime.utcnow().isoformat() + \"Z\",\n",
        "        \"docCount\": len(engine.documents),\n",
        "        \"termCount\": len(engine.word_locations),\n",
        "    }\n",
        "\n",
        "    fb_set(\"/indexes/lecture_search/latest/meta\", meta)\n",
        "    fb_set(\"/indexes/lecture_search/latest/terms\", index_payload)\n",
        "\n",
        "    return f\"‚úÖ Index saved correctly. terms={meta['termCount']}\"\n",
        "\n",
        "\n",
        "\n",
        "def save_iot_df_to_firebase(feed: str, df: pd.DataFrame, max_rows: int = 2000):\n",
        "    \"\"\"\n",
        "    Push IoT rows (created_at, value) into Firebase.\n",
        "    Dedup strategy: uses created_at as part of key if needed, but simplest: push rows.\n",
        "    \"\"\"\n",
        "    if df is None or df.empty:\n",
        "        return f\"‚ö†Ô∏è No data for feed={feed}\"\n",
        "\n",
        "    df2 = df.copy()\n",
        "    df2[\"created_at\"] = df2[\"created_at\"].astype(str)\n",
        "\n",
        "    # Keep last N rows to avoid massive uploads in one click\n",
        "    rows = df2.tail(max_rows).to_dict(orient=\"records\")\n",
        "\n",
        "    base_path = f\"/iot/raw/{feed}\"\n",
        "    for r in rows:\n",
        "        fb_push(base_path, r)\n",
        "\n",
        "    return f\"‚úÖ Saved {len(rows)} rows to Firebase under {base_path}\"\n",
        "\n",
        "# --- 8. Big Data (Spark) Analytics on IoT ---\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, min as spark_min, max as spark_max, avg as spark_avg, stddev as spark_stddev\n",
        "\n",
        "SPARK = None\n",
        "\n",
        "def spark_get_session():\n",
        "    global SPARK\n",
        "    if SPARK is not None:\n",
        "        return SPARK\n",
        "    SPARK = SparkSession.builder.appName(\"IoT Big Data Analytics\").getOrCreate()\n",
        "    return SPARK\n",
        "\n",
        "def compute_bigdata_analytics_from_df(feed: str, df: pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Big data analytics for one feed:\n",
        "    - Required: min/max (per tutorial)\n",
        "    - Extra: avg/std + anomaly count (z-score style)\n",
        "    Saves results to Firebase under /iot/analytics/latest/{feed}\n",
        "    \"\"\"\n",
        "    if df is None or df.empty:\n",
        "        return None, f\"‚ö†Ô∏è No data for {feed}\"\n",
        "\n",
        "    # Prepare clean pandas\n",
        "    dfx = df[[\"created_at\", \"value\"]].dropna().copy()\n",
        "    dfx[\"created_at\"] = pd.to_datetime(dfx[\"created_at\"])\n",
        "    dfx[\"value\"] = pd.to_numeric(dfx[\"value\"], errors=\"coerce\").dropna()\n",
        "\n",
        "    if dfx.empty:\n",
        "        return None, f\"‚ö†Ô∏è No numeric data for {feed}\"\n",
        "\n",
        "    spark = spark_get_session()\n",
        "\n",
        "    # Spark DF\n",
        "    sdf = spark.createDataFrame(dfx.assign(created_at=dfx[\"created_at\"].astype(str)).to_dict(orient=\"records\"))\n",
        "\n",
        "    # Spark aggregations\n",
        "    agg_row = sdf.agg(\n",
        "        spark_min(col(\"value\")).alias(\"min\"),\n",
        "        spark_max(col(\"value\")).alias(\"max\"),\n",
        "        spark_avg(col(\"value\")).alias(\"avg\"),\n",
        "        spark_stddev(col(\"value\")).alias(\"stddev\"),\n",
        "    ).collect()[0]\n",
        "\n",
        "    stats = {\n",
        "        \"feed\": feed,\n",
        "        \"count\": int(sdf.count()),\n",
        "        \"min\": float(agg_row[\"min\"]) if agg_row[\"min\"] is not None else None,\n",
        "        \"max\": float(agg_row[\"max\"]) if agg_row[\"max\"] is not None else None,\n",
        "        \"avg\": float(agg_row[\"avg\"]) if agg_row[\"avg\"] is not None else None,\n",
        "        \"stddev\": float(agg_row[\"stddev\"]) if agg_row[\"stddev\"] is not None else None,\n",
        "    }\n",
        "\n",
        "    # MapReduce-style min/max using RDD (conceptual match)\n",
        "    rdd = sdf.select(\"value\").rdd.map(lambda row: float(row[\"value\"]))\n",
        "    mr_min = rdd.reduce(lambda a, b: a if a < b else b)\n",
        "    mr_max = rdd.reduce(lambda a, b: a if a > b else b)\n",
        "    stats[\"mapreduce_min\"] = float(mr_min)\n",
        "    stats[\"mapreduce_max\"] = float(mr_max)\n",
        "\n",
        "    # Simple anomaly count using z-score (if stddev exists and > 0)\n",
        "    if stats[\"stddev\"] and stats[\"stddev\"] > 0:\n",
        "        mean = stats[\"avg\"]\n",
        "        sd = stats[\"stddev\"]\n",
        "        anomalies = dfx[(dfx[\"value\"] - mean).abs() > 3 * sd]\n",
        "        stats[\"anomalyCount_3sigma\"] = int(len(anomalies))\n",
        "    else:\n",
        "        stats[\"anomalyCount_3sigma\"] = 0\n",
        "\n",
        "    stats[\"generatedAt\"] = datetime.utcnow().isoformat() + \"Z\"\n",
        "\n",
        "    # Save to Firebase\n",
        "    fb_set(f\"/iot/analytics/latest/{feed}\", stats)\n",
        "\n",
        "    return stats, f\"‚úÖ Big data analytics computed & saved for {feed}\"\n",
        "\n",
        "def run_bigdata_pipeline(chk_temp, chk_hum, chk_soil, limit):\n",
        "    feeds = []\n",
        "    if chk_temp: feeds.append(\"temperature\")\n",
        "    if chk_hum: feeds.append(\"humidity\")\n",
        "    if chk_soil: feeds.append(\"soil\")\n",
        "\n",
        "    if not feeds:\n",
        "        return pd.DataFrame([]), None, \"‚ö†Ô∏è Choose at least one feed.\"\n",
        "\n",
        "    all_stats = []\n",
        "    last_fig = None\n",
        "    logs = []\n",
        "\n",
        "    for feed in feeds:\n",
        "        df = fetch_data_as_df(feed, int(limit), save_to_firebase=True)\n",
        "        stats, msg = compute_bigdata_analytics_from_df(feed, df)\n",
        "        logs.append(msg)\n",
        "\n",
        "        if stats:\n",
        "            all_stats.append(stats)\n",
        "\n",
        "        # Plot last selected feed\n",
        "        if df is not None and not df.empty:\n",
        "            last_fig = create_plot(df, f\"{feed} Trend (for analytics)\", \"green\")\n",
        "\n",
        "    return pd.DataFrame(all_stats), last_fig, \"\\n\".join(logs)\n",
        "\n",
        "def load_latest_analytics_from_firebase():\n",
        "    data = fb_get(\"/iot/analytics/latest\")\n",
        "    if not data:\n",
        "        return pd.DataFrame([])\n",
        "\n",
        "    # data is {feed: stats}\n",
        "    rows = []\n",
        "    for feed, stats in data.items():\n",
        "        if isinstance(stats, dict):\n",
        "            rows.append(stats)\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# NEW: CHATBOT LOGIC (GenAI) - FIXED to 2.5 Flash\n",
        "# ==========================================\n",
        "def chat_with_gemini(message, history):\n",
        "    \"\"\"\n",
        "    Chatbot function for Tab 7.\n",
        "    Uses the global Gemini API Key and explicitly forces gemini-2.5-flash.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Use existing configured model or configure fresh\n",
        "        genai.configure(api_key=GEMINI_API_KEY)\n",
        "\n",
        "        # NEW CODE: Force 2.5 Flash as requested by user\n",
        "        target_model = \"models/gemini-2.5-flash\"\n",
        "\n",
        "        # OLD CODE: target_model = \"models/gemini-1.5-flash\"\n",
        "\n",
        "        model = genai.GenerativeModel(target_model)\n",
        "\n",
        "        # System Context\n",
        "        system_instruction = (\n",
        "            \"You are a helpful AI assistant for a Smart Plant IoT System. \"\n",
        "            \"You help users understand plant health, sensor data (Temperature, Humidity, Soil Moisture), \"\n",
        "            \"and big data analytics. \"\n",
        "            \"Be concise, friendly, and professional.\"\n",
        "        )\n",
        "\n",
        "        chat = model.start_chat(history=[])\n",
        "        # Send system context + user message\n",
        "        full_prompt = f\"{system_instruction}\\n\\nUser Question: {message}\"\n",
        "\n",
        "        response = chat.send_message(full_prompt)\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        return f\"‚ö†Ô∏è Error interacting with Gemini: {str(e)}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UdnGhALsW2CM",
        "outputId": "18fb6729-a717-4f85-fe40-ec4fe5d1ab02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Connecting to Google Drive... Please approve.\n",
            "‚úÖ Drive Connected!\n",
            "üîÑ Connecting to Firebase Realtime DB...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_auth_httplib2:httplib2 transport does not support per-request timeout. Set the timeout when constructing the httplib2.Http instance.\n",
            "WARNING:google_auth_httplib2:httplib2 transport does not support per-request timeout. Set the timeout when constructing the httplib2.Http instance.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Firebase Connected!\n",
            "üìÇ Found 5 documents.\n",
            "üìö Building Search Index...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1816835948.py:463: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  \"createdAt\": datetime.utcnow().isoformat() + \"Z\",\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Index saved correctly. terms=6345\n",
            "ü§ñ Active Text AI: models/gemini-2.5-flash\n",
            "üß† Vision model will load only when you click 'Analyze Leaf' in Tab 1.\n",
            "\n",
            "üöÄ Launching System...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3523886767.py:71: DeprecationWarning: The 'theme' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'theme' to Blocks.launch() instead.\n",
            "  with gr.Blocks(theme=theme, title=\"Smart Plant System\") as demo:\n",
            "/tmp/ipython-input-3523886767.py:229: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot(label=\"Gemini Assistant\", height=400)\n",
            "/tmp/ipython-input-3523886767.py:229: DeprecationWarning: The default value of 'allow_tags' in gr.Chatbot will be changed from False to True in Gradio 6.0. You will need to explicitly set allow_tags=False if you want to disable tags in your chatbot.\n",
            "  chatbot = gr.Chatbot(label=\"Gemini Assistant\", height=400)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://83ce6ef1443d1422f0.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://83ce6ef1443d1422f0.gradio.live\" width=\"100%\" height=\"900\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/humidity\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/soil\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/temperature\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/humidity\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/temperature\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/soil\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/temperature\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/soil\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/humidity\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/soil\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/humidity\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/temperature\n",
            "‚úÖ Saved 20 rows to Firebase under /iot/raw/humidity\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/soil\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/temperature\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/humidity\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/soil\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/humidity\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/temperature\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/humidity\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/soil\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/temperature\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/humidity\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/temperature\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/soil\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/temperature\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/humidity\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/soil\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1816835948.py:564: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  stats[\"generatedAt\"] = datetime.utcnow().isoformat() + \"Z\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/temperature\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/soil\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/humidity\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/temperature\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/soil\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/humidity\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/humidity\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/temperature\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/soil\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/soil\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/temperature\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/humidity\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/temperature\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/humidity\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/soil\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/temperature\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/humidity\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/soil\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/soil\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/temperature\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/humidity\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/soil\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/temperature\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/humidity\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/humidity\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/temperature\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/soil\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/soil\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/humidity\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/temperature\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/soil\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/temperature\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/humidity\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/soil\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/humidity\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/temperature\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/humidity\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/temperature\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/soil\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/humidity\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/temperature\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/soil\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/soil\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/humidity\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/temperature\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/temperature\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/humidity\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/soil\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/temperature\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/soil\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/humidity\n",
            "‚úÖ Saved 20 rows to Firebase under /iot/raw/temperature\n",
            "‚úÖ Saved 20 rows to Firebase under /iot/raw/humidity\n",
            "‚úÖ Saved 20 rows to Firebase under /iot/raw/soil\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/soil\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/temperature\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/humidity\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/humidity\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/temperature\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/soil\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/humidity\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/temperature\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/soil\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/soil\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/temperature\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/humidity\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/temperature\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/humidity\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/soil\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/humidity\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/temperature\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/soil\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/temperature\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/humidity\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/soil\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/temperature\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/soil\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/humidity\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/humidity\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/soil\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/temperature\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/soil\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/temperature\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/humidity\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/soil\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/humidity\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/temperature\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/temperature\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/soil\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/humidity\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/soil\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/humidity\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/temperature\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/soil\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/humidity\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/temperature\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/humidity\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/temperature\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/soil\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/soil\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/humidity\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/temperature\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/temperature\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/soil\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/humidity\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/humidity\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/soil\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/temperature\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/humidity\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/temperature\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/soil\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/temperature\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/humidity\n",
            "‚úÖ Saved 1 rows to Firebase under /iot/raw/soil\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://83ce6ef1443d1422f0.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# ==========================================\n",
        "# PART 3: MAIN EXECUTION\n",
        "# ==========================================\n",
        "\n",
        "print(\"üîÑ Connecting to Google Drive... Please approve.\")\n",
        "try:\n",
        "    auth.authenticate_user()\n",
        "    drive_service = build('drive', 'v3')\n",
        "    print(\"‚úÖ Drive Connected!\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Drive Error: {e}\")\n",
        "\n",
        "# üî• Firebase init (set your DB URL)\n",
        "# Example URL format (from Firebase Realtime DB console):\n",
        "# https://<PROJECT_ID>-default-rtdb.<region>.firebasedatabase.app/\n",
        "FIREBASE_DB_URL = \"https://panther-28ba1-default-rtdb.europe-west1.firebasedatabase.app/\"\n",
        "\n",
        "print(\"üîÑ Connecting to Firebase Realtime DB...\")\n",
        "try:\n",
        "    firebase_init(FIREBASE_DB_URL, \"/content/serviceAccountKey.json\")\n",
        "    print(\"‚úÖ Firebase Connected!\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Firebase Error: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 1. Load Files & Build Index\n",
        "files = get_files_from_folder(FOLDER_ID)\n",
        "if files:\n",
        "    print(f\"üìÇ Found {len(files)} documents.\")\n",
        "    for i, file in enumerate(files, 1):\n",
        "        doc_id = str(i)\n",
        "        DOC_TITLES[doc_id] = file['name']\n",
        "        content = fetch_gdoc_content(file['id']).strip()\n",
        "        if content:\n",
        "            ARTICLES[doc_id] = content\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No documents found or wrong Folder ID.\")\n",
        "\n",
        "engine = LectureSearchEngine()\n",
        "if ARTICLES:\n",
        "    print(\"üìö Building Search Index...\")\n",
        "    engine.build_index(ARTICLES, DOC_TITLES)\n",
        "\n",
        "    # Save index to Firebase\n",
        "    try:\n",
        "        msg = save_index_to_firebase(engine)\n",
        "        print(msg)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed saving index to Firebase: {e}\")\n",
        "\n",
        "\n",
        "# 2. Setup AI Models (Text model only at startup)\n",
        "ACTIVE_MODEL = get_working_model()\n",
        "print(f\"ü§ñ Active Text AI: {ACTIVE_MODEL}\")\n",
        "\n",
        "# NOTE: Vision model is now lazy-loaded (no startup download)\n",
        "print(\"üß† Vision model will load only when you click 'Analyze Leaf' in Tab 1.\")\n",
        "\n",
        "# 3. Launch Gradio UI\n",
        "print(\"\\nüöÄ Launching System...\")\n",
        "\n",
        "theme = gr.themes.Soft(\n",
        "    primary_hue=\"green\",\n",
        "    secondary_hue=\"emerald\",\n",
        ")\n",
        "\n",
        "\n",
        "with gr.Blocks(theme=theme, title=\"Smart Plant System\") as demo:\n",
        "\n",
        "    # Header Section\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=5):\n",
        "            gr.Markdown(\"# üå± Smart Plant System Ultimate\")\n",
        "        with gr.Column(scale=1):\n",
        "            mode_btn = gr.Button(\"üåó Light/Dark Mode\", variant=\"secondary\")\n",
        "            mode_btn.click(None, None, None, js=\"() => document.body.classList.toggle('dark')\")\n",
        "\n",
        "    with gr.Tabs():\n",
        "\n",
        "        # Tab 1: Image AI\n",
        "        with gr.TabItem(\"1. Image (AI) üì∏\"):\n",
        "            gr.Markdown(\"### üçÉ Plant Disease Detection\")\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    img_input = gr.Image(height=300, label=\"Upload Leaf Photo üì∑\", type=\"numpy\")\n",
        "                    analyze_btn = gr.Button(\"üîç Analyze Leaf\", variant=\"primary\")\n",
        "                with gr.Column():\n",
        "                    img_out = gr.Textbox(label=\"AI Diagnosis ü§ñ\", lines=4, placeholder=\"Waiting for image...\")\n",
        "            analyze_btn.click(analyze_image, inputs=img_input, outputs=img_out)\n",
        "\n",
        "\n",
        "        # Tab 2: IoT Data & Leaderboard\n",
        "        with gr.TabItem(\"2. IoT Data üìä\"):\n",
        "            gr.Markdown(\"### üì° Sensor Real-Time Value\")\n",
        "\n",
        "            # 1. IoT Values Row\n",
        "            with gr.Row():\n",
        "                v1 = gr.Textbox(label=\"Current Temperature üå°Ô∏è\", lines=1)\n",
        "                v2 = gr.Textbox(label=\"Current Humidity üíß\", lines=1)\n",
        "                v3 = gr.Textbox(label=\"Current Soil Moisture üåø\", lines=1)\n",
        "\n",
        "            # Last Updated Label (Visual Proof)\n",
        "            lbl_update = gr.Markdown(\"‚è≥ Waiting for update...\", elem_id=\"update_lbl\")\n",
        "\n",
        "            gr.Markdown(\"---\")\n",
        "\n",
        "            # --- LEADERBOARD & WATERING SECTION ---\n",
        "            with gr.Row():\n",
        "                # Left Side: Controls\n",
        "                with gr.Column(scale=1):\n",
        "                    gr.Markdown(\"### üéÆ Remote Actions\")\n",
        "                    # Water Button\n",
        "                    btn_water = gr.Button(\"üöø Remote Water (+5 pts) üíß\", variant=\"primary\", size=\"lg\")\n",
        "\n",
        "                    gr.Markdown(\"### ‚öôÔ∏è Settings\")\n",
        "                    lim = gr.Number(value=20, label=\"Data Limit üî¢\")\n",
        "                    btn_json = gr.Button(\"üíæ Export as JSON\", variant=\"secondary\")\n",
        "                    f_out = gr.File(height=50, label=\"Download JSON\", visible=False)\n",
        "\n",
        "                # Right Side: Leaderboard\n",
        "                with gr.Column(scale=2):\n",
        "                    gr.Markdown(\"### üèÜ Top Gardeners (Leaderboard)\")\n",
        "                    leaderboard_table = gr.Dataframe(\n",
        "                        value=get_leaderboard_df,\n",
        "                        headers=[\"Rank\", \"Player\", \"Score\"],\n",
        "                        interactive=False,\n",
        "                        row_count=6\n",
        "                    )\n",
        "\n",
        "            # --- LOGIC ---\n",
        "            # Timer ticks - updates values + timestamp (PARALLEL FETCH)\n",
        "            timer = gr.Timer(5)\n",
        "            # Note: We now output to 4 components (3 values + 1 label)\n",
        "            timer.tick(fetch_sensor_values, inputs=[lim], outputs=[v1, v2, v3, lbl_update])\n",
        "\n",
        "            # Export JSON (Uses full limit)\n",
        "            btn_json.click(export_json_data, inputs=[lim], outputs=[f_out])\n",
        "\n",
        "            # Watering Logic\n",
        "            btn_water.click(update_leaderboard, inputs=None, outputs=leaderboard_table)\n",
        "\n",
        "          # Tab: Big Data Observations\n",
        "        with gr.TabItem(\"3. Big Data Observations üìà\"):\n",
        "            gr.Markdown(\n",
        "                \"### üß† Big Data Analytics on IoT Streams\\n\"\n",
        "                \"- Computes **min/max** per parameter (MapReduce requirement) + extra insights.\\n\"\n",
        "                \"- Saves results to Firebase.\\n\"\n",
        "            )\n",
        "\n",
        "            with gr.Row():\n",
        "                with gr.Column(scale=1):\n",
        "                    bt1 = gr.Checkbox(label=\"Temperature üå°Ô∏è\", value=True)\n",
        "                    bt2 = gr.Checkbox(label=\"Humidity üíß\", value=True)\n",
        "                    bt3 = gr.Checkbox(label=\"Soil Moisture üåø\", value=True)\n",
        "                    blim = gr.Number(value=20, label=\"Analytics Limit üî¢\")\n",
        "                    run_bd_btn = gr.Button(\"üöÄ Run Big Data Analytics\", variant=\"primary\")\n",
        "\n",
        "                    refresh_fb_btn = gr.Button(\"üîÑ Load Latest Analytics from Firebase\", variant=\"secondary\")\n",
        "\n",
        "                with gr.Column(scale=3):\n",
        "                    bd_table = gr.Dataframe(label=\"Analytics Table (saved to Firebase)\")\n",
        "                    bd_plot = gr.Plot(label=\"Trend Plot\")\n",
        "                    bd_log = gr.Textbox(label=\"Logs / Observations\", lines=6)\n",
        "\n",
        "            run_bd_btn.click(\n",
        "                run_bigdata_pipeline,\n",
        "                inputs=[bt1, bt2, bt3, blim],\n",
        "                outputs=[bd_table, bd_plot, bd_log]\n",
        "            )\n",
        "\n",
        "            refresh_fb_btn.click(\n",
        "                load_latest_analytics_from_firebase,\n",
        "                inputs=[],\n",
        "                outputs=[bd_table]\n",
        "            )\n",
        "\n",
        "\n",
        "        # Tab 3: Search Docs\n",
        "        with gr.TabItem(\"4. Search Docs üîç\"):\n",
        "            gr.Markdown(\"### üìö Knowledge Base Search\")\n",
        "            with gr.Row():\n",
        "                txt_in = gr.Textbox(label=\"Ask a Question\", placeholder=\"How does photosynthesis work?...\", scale=4)\n",
        "                search_btn = gr.Button(\"üîé Search\", variant=\"primary\", scale=1)\n",
        "\n",
        "            res_out = gr.Textbox(label=\"AI & Doc Results üí°\", lines=12)\n",
        "            search_btn.click(search_engine_rag, inputs=txt_in, outputs=res_out)\n",
        "\n",
        "            with gr.Accordion(\"üõ†Ô∏è Index Debug View\", open=False):\n",
        "                gr.Dataframe(get_index_table)\n",
        "\n",
        "        # Tab 4: Dashboard\n",
        "        with gr.TabItem(\"5. Dashboard üéõÔ∏è\"):\n",
        "            gr.Markdown(\"### ‚ö° Live Monitor\")\n",
        "            dash_btn = gr.Button(\"üîÑ Sync Live Data\", variant=\"primary\")\n",
        "\n",
        "            with gr.Row():\n",
        "                b1 = gr.Textbox(label=\"Temp üå°Ô∏è\")\n",
        "                b2 = gr.Textbox(label=\"Humidity üíß\")\n",
        "                b3 = gr.Textbox(label=\"Soil üåø\")\n",
        "                b4 = gr.Textbox(label=\"Status üö¶\")\n",
        "\n",
        "            with gr.Row():\n",
        "                dp1 = gr.Plot(label=\"Temp\")\n",
        "                dp2 = gr.Plot(label=\"Humidity\")\n",
        "            with gr.Row():\n",
        "                dp3 = gr.Plot(label=\"Soil\")\n",
        "\n",
        "            dash_btn.click(refresh_dashboard_real, outputs=[dp1, dp2, dp3, b1, b2, b3, b4])\n",
        "\n",
        "        # Tab 5: Report (UPDATED: Big Data PDF)\n",
        "        with gr.TabItem(\"6. PDF Report üìë\"):\n",
        "            gr.Markdown(\"### üìÑ Generate Professional Analytics Report\")\n",
        "            gr.Markdown(\"Generates a PDF based on the latest **Firebase Analytics** (Big Data Stats) instead of raw cache.\")\n",
        "            report_btn = gr.Button(\"üñ®Ô∏è Generate PDF (Big Data)\", variant=\"primary\")\n",
        "            with gr.Row():\n",
        "                pdf_file = gr.File(label=\"Download PDF üì•\")\n",
        "                report_log = gr.Textbox(label=\"Log üìù\", lines=2)\n",
        "            report_btn.click(generate_pdf_report, outputs=[pdf_file, report_log])\n",
        "\n",
        "        # NEW TAB: Chatbot\n",
        "        with gr.TabItem(\"7. AI Chatbot üí¨\"):\n",
        "            gr.Markdown(\"### ü§ñ Chat with Plant System AI\")\n",
        "            gr.Markdown(\"Ask anything about the system, garde6ning, or data!\")\n",
        "\n",
        "            # Using standard Chatbot UI components\n",
        "            chatbot = gr.Chatbot(label=\"Gemini Assistant\", height=400)\n",
        "            msg = gr.Textbox(label=\"Your Message\", placeholder=\"Ask me about the plant system...\")\n",
        "            clear = gr.Button(\"Clear Chat\")\n",
        "\n",
        "            def respond(message, chat_history):\n",
        "                # Call our Gemini helper\n",
        "                bot_message = chat_with_gemini(message, chat_history)\n",
        "                chat_history.append((message, bot_message))\n",
        "                return \"\", chat_history\n",
        "\n",
        "            msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
        "            clear.click(lambda: None, None, chatbot, queue=False)\n",
        "\n",
        "\n",
        "demo.launch(inline=True, height=900, debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}