{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOKTrSXoSdpb7myL1/yiUxg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0d1d69ff397a4abbb93a3cfd945ce8ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d3d2b0f79cf146989656254b501a8d41",
              "IPY_MODEL_1e6087b0dd014ac5ac82431eadafa37d",
              "IPY_MODEL_2945134b7f1a415e9e4bb88ef57b438e"
            ],
            "layout": "IPY_MODEL_914787d6a247474087ab731cd08b2dfa"
          }
        },
        "d3d2b0f79cf146989656254b501a8d41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49dd4c7a1ba044568440f352f1849940",
            "placeholder": "​",
            "style": "IPY_MODEL_6161f5a81d874ce59e678e958f9af091",
            "value": "Loading weights: 100%"
          }
        },
        "1e6087b0dd014ac5ac82431eadafa37d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_137cd340708647b499d9b4965a34c2bc",
            "max": 200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f98c99190edb481c8258a91b80fe06ba",
            "value": 200
          }
        },
        "2945134b7f1a415e9e4bb88ef57b438e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b579a90e0494037ab1c6f8b2361a20c",
            "placeholder": "​",
            "style": "IPY_MODEL_ee2f1010c9064255b78dcdcd27c06acc",
            "value": " 200/200 [00:01&lt;00:00, 159.32it/s, Materializing param=vit.layernorm.weight]"
          }
        },
        "914787d6a247474087ab731cd08b2dfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49dd4c7a1ba044568440f352f1849940": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6161f5a81d874ce59e678e958f9af091": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "137cd340708647b499d9b4965a34c2bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f98c99190edb481c8258a91b80fe06ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4b579a90e0494037ab1c6f8b2361a20c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee2f1010c9064255b78dcdcd27c06acc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff53c86ef6de4fe395f4591f00bdd937": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c1e8b23267ca4af081ef8137551cc3fa",
              "IPY_MODEL_8095200b2363469381988b2203c196e2",
              "IPY_MODEL_288a70c4aa2f4bcc883ba223e236e2b4"
            ],
            "layout": "IPY_MODEL_172e5a106a6e4767bdc956ed202c145a"
          }
        },
        "c1e8b23267ca4af081ef8137551cc3fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a6eb371642e46bfbc0a7df97cdb1679",
            "placeholder": "​",
            "style": "IPY_MODEL_c92a3214dbda4840bd2060022cedbfaf",
            "value": "Loading weights: 100%"
          }
        },
        "8095200b2363469381988b2203c196e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2cd7f9ffb1f43cfa838e0255b133fde",
            "max": 200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_72742d293f5e44d6b8c605871648db59",
            "value": 200
          }
        },
        "288a70c4aa2f4bcc883ba223e236e2b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29ccea6d3519460eb262751a8c1797f3",
            "placeholder": "​",
            "style": "IPY_MODEL_7696a19736fd4fe483b17d7d3efbec07",
            "value": " 200/200 [00:00&lt;00:00, 382.41it/s, Materializing param=vit.layernorm.weight]"
          }
        },
        "172e5a106a6e4767bdc956ed202c145a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a6eb371642e46bfbc0a7df97cdb1679": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c92a3214dbda4840bd2060022cedbfaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2cd7f9ffb1f43cfa838e0255b133fde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72742d293f5e44d6b8c605871648db59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "29ccea6d3519460eb262751a8c1797f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7696a19736fd4fe483b17d7d3efbec07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "643a0584d56c4ce9862ad4ef0bedab29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_88b6c6002a2e489e881eb6709e37cb74",
              "IPY_MODEL_b178156e03ef423d8fe44cd391ff2b05",
              "IPY_MODEL_2e9707c370ae4fc58fb09ac02875d372"
            ],
            "layout": "IPY_MODEL_d40d0f2c25ff46dabf5c53f63ae5de9c"
          }
        },
        "88b6c6002a2e489e881eb6709e37cb74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f98cd30ebcb344ae86ed35cd37d5c48e",
            "placeholder": "​",
            "style": "IPY_MODEL_602d73344d714f34bdb92481e07fc33c",
            "value": "Loading weights: 100%"
          }
        },
        "b178156e03ef423d8fe44cd391ff2b05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_647c33e5b5ac4e07806dd3b01abcee8e",
            "max": 200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8ddd87ce63d74a07a62391b826681c62",
            "value": 200
          }
        },
        "2e9707c370ae4fc58fb09ac02875d372": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9463d2c8238e4126aa6b8e2edb644829",
            "placeholder": "​",
            "style": "IPY_MODEL_198ae85be1a0457c8a8151ed40086d61",
            "value": " 200/200 [00:00&lt;00:00, 477.86it/s, Materializing param=vit.layernorm.weight]"
          }
        },
        "d40d0f2c25ff46dabf5c53f63ae5de9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f98cd30ebcb344ae86ed35cd37d5c48e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "602d73344d714f34bdb92481e07fc33c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "647c33e5b5ac4e07806dd3b01abcee8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ddd87ce63d74a07a62391b826681c62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9463d2c8238e4126aa6b8e2edb644829": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "198ae85be1a0457c8a8151ed40086d61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MichaelBillan/Cloud-Computing/blob/main/PROJECT_PANTHER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-J7C1WwXuDA"
      },
      "outputs": [],
      "source": [
        "# ================================================\n",
        "# PART 1: INSTALL, IMPORTS & SETTINGS (OPTIMIZED)\n",
        "# ================================================\n",
        "\n",
        "# --------- 0) Fast, safe installs: install ONLY if missing ----------\n",
        "import sys, importlib.util, subprocess\n",
        "\n",
        "def pip_install_if_missing(packages):\n",
        "    missing = []\n",
        "    for pkg in packages:\n",
        "        base = pkg.split(\"==\")[0].split(\">=\")[0].split(\"[\")[0]\n",
        "        module = {\n",
        "            \"google-genai\": \"google.genai\",\n",
        "        }.get(base, base.replace(\"-\", \"_\"))\n",
        "        if importlib.util.find_spec(module) is None:\n",
        "            missing.append(pkg)\n",
        "\n",
        "    if missing:\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", *missing])\n",
        "\n",
        "# Base features (UI, Drive, Gemini, NLTK, PDF, Firebase, Big Data, Vision)\n",
        "pip_install_if_missing([\n",
        "    \"gradio\",\n",
        "    \"nltk\",\n",
        "    \"fpdf\",\n",
        "    \"google-genai\",\n",
        "    \"google-api-python-client\",\n",
        "    \"firebase-admin\",\n",
        "    \"pyspark\",\n",
        "    \"transformers==4.30.2\"\n",
        "])\n",
        "\n",
        "# --------- 1) Imports (only what we actually use) ----------\n",
        "\n",
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "import requests\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "from requests import get as http_get\n",
        "from os import environ\n",
        "from bs4 import BeautifulSoup\n",
        "from collections import defaultdict\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "from google import genai\n",
        "\n",
        "from fpdf import FPDF\n",
        "from PIL import Image as PILImage\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "\n",
        "import firebase_admin\n",
        "from firebase_admin import credentials, db as firebase_db\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, min as spark_min, max as spark_max, avg as spark_avg, stddev as spark_stddev\n",
        "\n",
        "# Note: Importing the library is fast, we still load the MODEL lazily in Part 2.\n",
        "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
        "import torch\n",
        "\n",
        "GEMINI_API_KEY = \"\" # generated by Michael at 09/02\n",
        "\n",
        "BASE_URL = \"https://server-cloud-v645.onrender.com/\"\n",
        "MODEL_ID = \"wambugu71/crop_leaf_diseases_vit\"\n",
        "\n",
        "\n",
        "# --------- 3) NLTK downloads only if missing ----------\n",
        "def nltk_download_if_missing(resource_path, download_name=None):\n",
        "    try:\n",
        "        nltk.data.find(resource_path)\n",
        "    except LookupError:\n",
        "        nltk.download(download_name or resource_path.split(\"/\")[-1], quiet=True)\n",
        "\n",
        "nltk_download_if_missing(\"corpora/stopwords\", \"stopwords\")\n",
        "nltk_download_if_missing(\"tokenizers/punkt\", \"punkt\")\n",
        "\n",
        "# --------- 4) Globals ----------\n",
        "GLOBAL_CACHE = {\"temperature\": None, \"humidity\": None, \"soil\": None}\n",
        "DOC_TITLES = {}\n",
        "ARTICLES = {}\n",
        "drive_service = None\n",
        "engine = None\n",
        "GENAI_CLIENT = None\n",
        "plant_classifier = None\n",
        "FIREBASE_APP = None\n",
        "FIREBASE_DB_URL = None\n",
        "SPARK = None"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# PART 2: HELPER FUNCTIONS & CLASSES\n",
        "# ==========================================\n",
        "\n",
        "IL_TZ = pytz.timezone('Asia/Jerusalem') # Time zone configuration\n",
        "\n",
        "# ---------------------------\n",
        "# 1) WEB FETCH + MAIN TEXT EXTRACTOR\n",
        "# ---------------------------\n",
        "HEADERS = {\n",
        "    \"User-Agent\": (\n",
        "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
        "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
        "        \"Chrome/120.0.0.0 Safari/537.36\"\n",
        "    )\n",
        "}\n",
        "\n",
        "def fetch_html(url: str, timeout: int = 10) -> str:\n",
        "    r = requests.get(url, headers=HEADERS, timeout=timeout)\n",
        "    r.raise_for_status()\n",
        "    return r.text\n",
        "\n",
        "def _clean_text(text: str) -> str:\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "def _remove_noise(soup: BeautifulSoup) -> None:\n",
        "    for tag in soup([\"script\", \"style\", \"noscript\", \"header\", \"footer\", \"nav\", \"aside\"]):\n",
        "        tag.decompose()\n",
        "\n",
        "def extract_main_article_text(url: str, html: str) -> dict:\n",
        "\n",
        "    soup = BeautifulSoup(html, \"html.parser\")\n",
        "    _remove_noise(soup)\n",
        "\n",
        "    title = None\n",
        "    if soup.title and soup.title.get_text(strip=True):\n",
        "        title = soup.title.get_text(strip=True)\n",
        "\n",
        "    h1 = soup.find(\"h1\")\n",
        "    if h1 and h1.get_text(strip=True):\n",
        "        title = h1.get_text(strip=True)\n",
        "\n",
        "    selectors = [\n",
        "      \"div.main-content\",\n",
        "      \"div.c-article-body\",\n",
        "      \"article\",\n",
        "      \"main\",\n",
        "      \"div[itemprop='articleBody']\",\n",
        "      \"section[aria-labelledby='abstract']\",\n",
        "      \"div#content\",\n",
        "      \"div#main-content\",\n",
        "    ]\n",
        "\n",
        "    chosen = None\n",
        "    for sel in selectors:\n",
        "        node = soup.select_one(sel)\n",
        "        if node:\n",
        "            txt = node.get_text(\" \", strip=True)\n",
        "            if txt and len(txt) > 600:\n",
        "                chosen = txt\n",
        "                break\n",
        "\n",
        "    # --- Fallback: pick the largest reasonable text block ---\n",
        "    if not chosen:\n",
        "        candidates = []\n",
        "        for node in soup.find_all([\"article\", \"main\", \"section\", \"div\"]):\n",
        "            txt = node.get_text(\" \", strip=True)\n",
        "            # keep only blocks that look like real content\n",
        "            if txt and len(txt) > 800:\n",
        "                candidates.append((len(txt), txt))\n",
        "        if candidates:\n",
        "            candidates.sort(key=lambda x: x[0], reverse=True)\n",
        "            chosen = candidates[0][1]\n",
        "\n",
        "    # Final fallback: whole page text (worst case)\n",
        "    if not chosen:\n",
        "        chosen = soup.get_text(\" \", strip=True)\n",
        "\n",
        "    return {\n",
        "        \"title\": title or url,\n",
        "        \"content\": _clean_text(chosen),\n",
        "        \"source\": url\n",
        "    }\n",
        "\n",
        "# ---------------------------\n",
        "# 2) BUILD YOUR ARTICLES/TITLES FROM URLS\n",
        "# ---------------------------\n",
        "def load_articles_from_web(urls: list[str]) -> tuple[dict, dict]:\n",
        "\n",
        "    for i, url in enumerate(urls, 1):\n",
        "        doc_id = str(i)\n",
        "        try:\n",
        "            html = fetch_html(url)\n",
        "            extracted = extract_main_article_text(url, html)\n",
        "\n",
        "            DOC_TITLES[doc_id] = extracted[\"title\"]\n",
        "            ARTICLES[doc_id] = extracted[\"content\"]\n",
        "\n",
        "            print(f\"✅ Loaded [{doc_id}] {extracted['title']}\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Failed loading {url}: {e}\")\n",
        "\n",
        "    return ARTICLES, DOC_TITLES\n",
        "\n",
        "\n",
        "# --- 2. Search Engine Logic (Class) ---\n",
        "class LectureSearchEngine:\n",
        "    def __init__(self):\n",
        "        self.word_locations = defaultdict(list)\n",
        "        self.documents = {}\n",
        "        self.titles = {}\n",
        "        self.stemmer = PorterStemmer()\n",
        "        self.stop_words = set(stopwords.words('english'))\n",
        "        self.stop_words.update({'a', 'an', 'the', 'and', 'or', 'in', 'on', 'at', 'to', 'for', 'of', 'with'})\n",
        "\n",
        "    def stem_word(self, word):\n",
        "        return self.stemmer.stem(word.lower())\n",
        "\n",
        "    def build_index(self, docs, titles):\n",
        "        self.documents = docs\n",
        "        self.titles = titles\n",
        "        self.word_locations.clear()\n",
        "\n",
        "        for doc_id, content in self.documents.items():\n",
        "            raw_words = re.findall(r'\\w+', content.lower())\n",
        "            word_counts = defaultdict(int)\n",
        "\n",
        "            for word in raw_words:\n",
        "                if word not in self.stop_words:\n",
        "                    word_counts[self.stem_word(word)] += 1\n",
        "\n",
        "            for word, count in word_counts.items():\n",
        "                self.word_locations[word].append((doc_id, count))\n",
        "\n",
        "    def get_context(self, content, query_words, window=180):\n",
        "        content_lower = content.lower()\n",
        "        best_idx = -1\n",
        "\n",
        "        for word in query_words:\n",
        "            root = word[:4] if len(word) > 4 else word\n",
        "            idx = content_lower.find(root)\n",
        "\n",
        "            if idx != -1:\n",
        "                best_idx = idx\n",
        "                break\n",
        "\n",
        "        if best_idx != -1:\n",
        "            start = max(0, best_idx - 60)\n",
        "            end = min(len(content), best_idx + window)\n",
        "            return \"...\" + content[start:end].replace(\"\\n\", \" \") + \"...\"\n",
        "        return content[:220].replace(\"\\n\", \" \") + \"...\"\n",
        "\n",
        "    def search(self, query, num_results=3):\n",
        "        raw_query_words = [w.lower() for w in re.findall(r'\\w+', query) if w.lower() not in self.stop_words]\n",
        "        stemmed_query_words = [self.stem_word(w) for w in raw_query_words]\n",
        "\n",
        "        if not stemmed_query_words:\n",
        "            return []\n",
        "\n",
        "        page_scores = defaultdict(lambda: {'matches': 0, 'total_freq': 0})\n",
        "\n",
        "        for word in stemmed_query_words:\n",
        "            for doc_id, freq in self.word_locations.get(word, []):\n",
        "                page_scores[doc_id]['matches'] += 1\n",
        "                page_scores[doc_id]['total_freq'] += freq\n",
        "\n",
        "        ranked = [(doc_id, s['matches'], s['total_freq']) for doc_id, s in page_scores.items()]\n",
        "        ranked.sort(key=lambda x: (x[1], x[2]), reverse=True)\n",
        "\n",
        "        results = []\n",
        "        for doc_id, matches, total_freq in ranked[:num_results]:\n",
        "            title = self.titles.get(doc_id, \"Unknown\")\n",
        "            content = self.documents.get(doc_id, \"\")\n",
        "            context = self.get_context(content, raw_query_words)\n",
        "            results.append({\n",
        "                'title': title,\n",
        "                'score': f\"Matches: {matches}, Freq: {total_freq}\",\n",
        "                'context': context\n",
        "            })\n",
        "        return results\n",
        "\n",
        "\n",
        "# --- 3. Gemini & RAG Helpers ---\n",
        "def get_genai_client():\n",
        "    global GENAI_CLIENT\n",
        "    if GENAI_CLIENT is None:\n",
        "        GENAI_CLIENT = genai.Client(api_key=GEMINI_API_KEY)\n",
        "    return GENAI_CLIENT\n",
        "\n",
        "def get_working_model():\n",
        "    return \"gemini-2.5-flash\"\n",
        "\n",
        "def search_engine_rag(query):\n",
        "    if not ARTICLES:\n",
        "        return \"⚠️ Error: No documents loaded.\"\n",
        "    results = engine.search(query)\n",
        "    if not results:\n",
        "        return f\"No results found for: '{query}'\"\n",
        "\n",
        "    output_log = f\"🔎 Found {len(results)} docs (Ranked by Matches & Freq)\\n\" + \"=\" * 40 + \"\\n\"\n",
        "    context_text = []\n",
        "\n",
        "    for res in results:\n",
        "        output_log += f\"\\n📄 [{res['title']}] ({res['score']})\\n - {res['context']}\\n\"\n",
        "        context_text.append(f\"Source ({res['title']}): {res['context']}\")\n",
        "\n",
        "    try:\n",
        "        client = get_genai_client()\n",
        "        prompt = (\n",
        "            f\"Question: {query}\\n\"\n",
        "            f\"Base your answer ONLY on the following context:\\n\" + \"\\n\".join(context_text)\n",
        "        )\n",
        "\n",
        "        response = client.models.generate_content(\n",
        "            model=\"gemini-2.5-flash\",\n",
        "            contents=prompt\n",
        "        )\n",
        "        gemini_summary = f\"\\n🤖 AI Answer:\\n{response.text}\\n\"\n",
        "    except Exception as e:\n",
        "        gemini_summary = f\"\\n(AI Error: {e})\\n\"\n",
        "\n",
        "\n",
        "    return gemini_summary + \"\\n\" + output_log\n",
        "\n",
        "def get_index_table():\n",
        "    data = []\n",
        "    if engine:\n",
        "        for i, (word, locs) in enumerate(engine.word_locations.items()):\n",
        "            if i >= 100:\n",
        "                break\n",
        "            data.append({\"term\": word, \"docs\": str(locs)})\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "\n",
        "# --- 4. IoT Helpers ---\n",
        "def fetch_data_as_df(feed, limit, save_to_firebase=True):\n",
        "    try:\n",
        "        resp = http_get(f\"{BASE_URL}/history\", params={\"feed\": feed, \"limit\": limit}, timeout=3)\n",
        "        data = resp.json()\n",
        "        if \"data\" in data and len(data[\"data\"]) > 0:\n",
        "            df = pd.DataFrame(data[\"data\"])\n",
        "\n",
        "            # --- TIMEZONE FIX START ---\n",
        "            df[\"created_at\"] = pd.to_datetime(df[\"created_at\"])\n",
        "            if df[\"created_at\"].dt.tz is None:\n",
        "                df[\"created_at\"] = df[\"created_at\"].dt.tz_localize('UTC')\n",
        "            df[\"created_at\"] = df[\"created_at\"].dt.tz_convert(IL_TZ)\n",
        "            df[\"created_at\"] = df[\"created_at\"].dt.tz_localize(None)\n",
        "            # --- TIMEZONE FIX END ---\n",
        "\n",
        "            df[\"value\"] = pd.to_numeric(df[\"value\"], errors=\"coerce\")\n",
        "            df = df.sort_values(\"created_at\")\n",
        "            GLOBAL_CACHE[feed] = df\n",
        "\n",
        "            if save_to_firebase:\n",
        "              try:\n",
        "                msg = save_iot_df_to_firebase(feed, df)\n",
        "                print(msg)\n",
        "              except Exception as e:\n",
        "                print(f\"Error saving to Firebase: {e}\")\n",
        "\n",
        "            return df\n",
        "    except:\n",
        "        return None\n",
        "    return None\n",
        "\n",
        "\n",
        "def create_plot(df, title, color):\n",
        "    if df is None or df.empty:\n",
        "        return None\n",
        "    fig, ax = plt.subplots(figsize=(8, 3.5))\n",
        "    ax.plot(df[\"created_at\"], df[\"value\"], marker='.', linestyle='-', color=color, linewidth=1.5)\n",
        "    ax.set_title(title)\n",
        "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "LEADERBOARD_DATA = [\n",
        "    {\"Player\": \"Foaad\", \"Score\": 255},\n",
        "    {\"Player\": \"You 🫵\", \"Score\": 245},\n",
        "    {\"Player\": \"Michael\", \"Score\": 90},\n",
        "    {\"Player\": \"Yazan\", \"Score\": 75},\n",
        "    {\"Player\": \"Baraah\", \"Score\": 60},\n",
        "    {\"Player\": \"Rami\", \"Score\": 15}\n",
        "]\n",
        "\n",
        "def get_leaderboard_df():\n",
        "    df = pd.DataFrame(LEADERBOARD_DATA)\n",
        "    df = df.sort_values(by=\"Score\", ascending=False).reset_index(drop=True)\n",
        "    df.insert(0, 'Rank', range(1, 1 + len(df)))\n",
        "    return df\n",
        "\n",
        "def update_leaderboard():\n",
        "    global LEADERBOARD_DATA\n",
        "    for player in LEADERBOARD_DATA:\n",
        "        if \"You\" in player[\"Player\"]:\n",
        "            player[\"Score\"] += 5\n",
        "            break\n",
        "    return get_leaderboard_df()\n",
        "\n",
        "# --- OPTIMIZED PARALLEL FETCH (LIMIT=1) ---\n",
        "def fetch_sensor_values(ignored_limit):\n",
        "    \"\"\"\n",
        "    Fetches ONLY the latest value (limit=1) for all sensors in PARALLEL.\n",
        "    \"\"\"\n",
        "    val_temp, val_hum, val_soil = \"Loading...\", \"Loading...\", \"Loading...\"\n",
        "    REAL_TIME_LIMIT = 1\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=3) as executor:\n",
        "        future_t = executor.submit(fetch_data_as_df, \"temperature\", REAL_TIME_LIMIT)\n",
        "        future_h = executor.submit(fetch_data_as_df, \"humidity\", REAL_TIME_LIMIT)\n",
        "        future_s = executor.submit(fetch_data_as_df, \"soil\", REAL_TIME_LIMIT)\n",
        "\n",
        "        df_t = future_t.result()\n",
        "        df_h = future_h.result()\n",
        "        df_s = future_s.result()\n",
        "\n",
        "    if df_t is not None and not df_t.empty:\n",
        "        val_temp = f\"{df_t.iloc[-1]['value']} °C\"\n",
        "    else:\n",
        "        val_temp = \"---\"\n",
        "\n",
        "    if df_h is not None and not df_h.empty:\n",
        "        val_hum = f\"{df_h.iloc[-1]['value']} %\"\n",
        "    else:\n",
        "        val_hum = \"---\"\n",
        "\n",
        "    if df_s is not None and not df_s.empty:\n",
        "        val_soil = str(df_s.iloc[-1]['value'])\n",
        "    else:\n",
        "        val_soil = \"---\"\n",
        "\n",
        "    current_time = datetime.now(IL_TZ).strftime(\"%H:%M:%S\")\n",
        "    update_msg = f\"⏱️ Last Updated (IL): {current_time}\"\n",
        "\n",
        "    return val_temp, val_hum, val_soil, update_msg\n",
        "\n",
        "def export_json_data(limit):\n",
        "    export_data = {}\n",
        "    feeds = [\"temperature\", \"humidity\", \"soil\"]\n",
        "\n",
        "    for feed in feeds:\n",
        "        df = fetch_data_as_df(feed, limit)\n",
        "        if df is not None and not df.empty:\n",
        "            export_data[feed] = df.to_dict(orient=\"records\")\n",
        "\n",
        "    json_filename = \"iot_data.json\"\n",
        "    try:\n",
        "        with open(json_filename, 'w') as f:\n",
        "            json.dump(export_data, f, default=str)\n",
        "        return gr.File(value=json_filename, visible=True)\n",
        "    except Exception as e:\n",
        "        return gr.File(visible=False)\n",
        "\n",
        "def refresh_dashboard_real():\n",
        "    limit = 20\n",
        "    df_t = fetch_data_as_df(\"temperature\", limit)\n",
        "    df_h = fetch_data_as_df(\"humidity\", limit)\n",
        "    df_s = fetch_data_as_df(\"soil\", limit)\n",
        "\n",
        "    fig_t = create_plot(df_t, \"Temp Trend\", \"#ff6b6b\")\n",
        "    fig_h = create_plot(df_h, \"Hum Trend\", \"#4ecdc4\")\n",
        "    fig_s = create_plot(df_s, \"Soil Trend\", \"#8d6e63\")\n",
        "\n",
        "    val_t = df_t.iloc[-1][\"value\"] if df_t is not None and not df_t.empty else 0\n",
        "    val_h = df_h.iloc[-1][\"value\"] if df_h is not None and not df_h.empty else 0\n",
        "    val_s = df_s.iloc[-1][\"value\"] if df_s is not None and not df_s.empty else 0\n",
        "\n",
        "    status = \"Warning ⚠️\" if val_t > 35 else \"OK ✅\"\n",
        "    return fig_t, fig_h, fig_s, f\"{val_t} °C\", f\"{val_h} %\", f\"{val_s}\", status\n",
        "\n",
        "\n",
        "\n",
        "# --- 5. Image AI Helpers (LAZY LOAD MODEL) ---\n",
        "# --- HF Model (Clean, Direct Load) ---\n",
        "\n",
        "def normalize_disease_label(label: str) -> str:\n",
        "    \"\"\"\n",
        "    Convert model labels into a clean phrase for Gemini:\n",
        "    e.g. 'Tomato___Late_blight' -> 'Tomato Late blight'\n",
        "         'Potato___healthy' -> 'Potato healthy'\n",
        "         'Tomato___Leaf_Mold' -> 'Tomato Leaf Mold'\n",
        "    \"\"\"\n",
        "    if not label:\n",
        "        return \"unknown disease\"\n",
        "\n",
        "    # common PlantVillage-style formatting\n",
        "    s = label.replace(\"___\", \" \").replace(\"__\", \" \").replace(\"_\", \" \")\n",
        "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
        "\n",
        "    # normalize some common tokens\n",
        "    s = s.replace(\"Leaf Mold\", \"Leaf mold\")\n",
        "    s = s.replace(\"Late blight\", \"late blight\")\n",
        "    s = s.replace(\"Early blight\", \"early blight\")\n",
        "\n",
        "    return s\n",
        "\n",
        "\n",
        "processor = AutoImageProcessor.from_pretrained(MODEL_ID)\n",
        "model = AutoModelForImageClassification.from_pretrained(MODEL_ID)\n",
        "\n",
        "def get_plant_model():\n",
        "    plant_processor = None\n",
        "    plant_model = None\n",
        "    if plant_processor is None:\n",
        "        plant_processor = AutoImageProcessor.from_pretrained(MODEL_ID)\n",
        "    if plant_model is None:\n",
        "        plant_model = AutoModelForImageClassification.from_pretrained(MODEL_ID)\n",
        "        plant_model.eval()\n",
        "    return plant_processor, plant_model\n",
        "\n",
        "def analyze_image(img):\n",
        "    if img is None:\n",
        "        return \"⚠️ Please upload an image.\"\n",
        "\n",
        "    try:\n",
        "        processor, model = get_plant_model()\n",
        "\n",
        "        # numpy -> PIL\n",
        "        pil_img = PILImage.fromarray(img.astype(\"uint8\")).convert(\"RGB\")\n",
        "\n",
        "        # preprocess\n",
        "        inputs = processor(images=pil_img, return_tensors=\"pt\")\n",
        "\n",
        "        # inference\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            probs = torch.softmax(outputs.logits, dim=-1)[0]\n",
        "            top_idx = int(torch.argmax(probs).item())\n",
        "            score = float(probs[top_idx].item())\n",
        "\n",
        "        raw_label = model.config.id2label.get(top_idx, str(top_idx))\n",
        "        nice_label = normalize_disease_label(raw_label)\n",
        "\n",
        "        # Decide \"healthy\" robustly (covers: healthy, Tomato healthy, Potato healthy, etc.)\n",
        "        is_healthy = \"healthy\" in raw_label.lower() or raw_label.lower().endswith(\" healthy\")\n",
        "\n",
        "        if is_healthy:\n",
        "            diagnosis = f\"✅ Healthy ({nice_label})\\nConfidence: {score:.1%}\"\n",
        "            advice = gemini_care_advice(\"healthy plant / general plant care\", score)\n",
        "            return diagnosis + \"\\n\\n🛠️ Care / Prevention:\\n\" + advice\n",
        "\n",
        "        diagnosis = f\"⚠️ Potential Issue: {nice_label}\\nConfidence: {score:.1%}\"\n",
        "\n",
        "        # Pass a clean disease string (better Gemini recommendations)\n",
        "        advice = gemini_care_advice(nice_label, score)\n",
        "\n",
        "        return diagnosis + \"\\n\\n🛠️ How to handle it:\\n\" + advice\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"❌ Error: {str(e)}\"\n",
        "\n",
        "\n",
        "\n",
        "# --- 6. PDF Report Helpers ---\n",
        "class PDFReport(FPDF):\n",
        "    def header(self):\n",
        "        self.set_font('Arial', 'B', 15)\n",
        "        self.cell(0, 10, 'IoT Big Data Analytics Report', 0, 1, 'C')\n",
        "        self.ln(5)\n",
        "\n",
        "    def chapter_title(self, title):\n",
        "        self.set_font('Arial', 'B', 12)\n",
        "        self.set_fill_color(200, 220, 255)\n",
        "        self.cell(0, 10, title, 0, 1, 'L', 1)\n",
        "        self.ln(4)\n",
        "\n",
        "    # Function to display Analytics Table in PDF\n",
        "    def chapter_analytics_table(self, df):\n",
        "        self.set_font('Arial', 'B', 10)\n",
        "        # Table Headers\n",
        "        self.cell(40, 8, 'Feed', 1)\n",
        "        self.cell(30, 8, 'Min', 1)\n",
        "        self.cell(30, 8, 'Max', 1)\n",
        "        self.cell(30, 8, 'Avg', 1)\n",
        "        self.cell(40, 8, 'Anomalies (3s)', 1)\n",
        "        self.ln()\n",
        "\n",
        "        self.set_font('Arial', '', 10)\n",
        "        if df is not None and not df.empty:\n",
        "            for _, row in df.iterrows():\n",
        "                feed_name = str(row.get('feed', 'N/A'))\n",
        "                val_min = f\"{float(row.get('min', 0)):.2f}\"\n",
        "                val_max = f\"{float(row.get('max', 0)):.2f}\"\n",
        "                val_avg = f\"{float(row.get('avg', 0)):.2f}\"\n",
        "                val_anom = str(row.get('anomalyCount_3sigma', 0))\n",
        "\n",
        "                self.cell(40, 8, feed_name, 1)\n",
        "                self.cell(30, 8, val_min, 1)\n",
        "                self.cell(30, 8, val_max, 1)\n",
        "                self.cell(30, 8, val_avg, 1)\n",
        "                self.cell(40, 8, val_anom, 1)\n",
        "                self.ln()\n",
        "        else:\n",
        "             self.cell(0, 8, \"No Analytics Data Available from Firebase\", 1, 1)\n",
        "        self.ln(10)\n",
        "\n",
        "    def chapter_body_raw(self, df):\n",
        "        self.set_font('Arial', '', 10)\n",
        "        self.cell(90, 8, 'Timestamp', 1)\n",
        "        self.cell(40, 8, 'Value', 1)\n",
        "        self.ln()\n",
        "        if df is not None and not df.empty:\n",
        "            for _, row in df.sort_values(\"created_at\", ascending=False).head(20).iterrows():\n",
        "                self.cell(90, 8, str(row['created_at']), 1)\n",
        "                self.cell(40, 8, str(row['value']), 1)\n",
        "                self.ln()\n",
        "        self.ln(10)\n",
        "\n",
        "# PDF Generation Function\n",
        "def generate_pdf_report():\n",
        "    # Fetch Analytics directly from Firebase\n",
        "    df_analytics = load_latest_analytics_from_firebase()\n",
        "\n",
        "    pdf = PDFReport()\n",
        "    pdf.add_page()\n",
        "\n",
        "    # Section 1: Big Data Overview\n",
        "    pdf.chapter_title(\"Big Data Analytics Overview (from Firebase)\")\n",
        "    pdf.chapter_analytics_table(df_analytics)\n",
        "\n",
        "    # Section 2: Raw Snippets\n",
        "    pdf.chapter_title(\"Recent Raw Data Snippets\")\n",
        "    for feed in [\"temperature\", \"humidity\", \"soil\"]:\n",
        "        # Try to get from cache or fetch small amount\n",
        "        df = GLOBAL_CACHE.get(feed)\n",
        "        if df is None:\n",
        "             df = fetch_data_as_df(feed, 10, save_to_firebase=False)\n",
        "\n",
        "        pdf.set_font('Arial', 'B', 10)\n",
        "        pdf.cell(0, 10, f\"Feed: {feed}\", 0, 1)\n",
        "        pdf.chapter_body_raw(df)\n",
        "\n",
        "    filename = \"iot_bigdata_report.pdf\"\n",
        "    pdf.output(filename)\n",
        "    return filename, f\"✅ Professional Report (Firebase Data) Saved to {filename}\"\n",
        "\n",
        "\n",
        "# --- 7. Firebase Realtime DB Helpers ---\n",
        "\n",
        "FIREBASE_SERVICE_ACCOUNT = {\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "def firebase_init(db_url: str):\n",
        "    global FIREBASE_APP, FIREBASE_DB_URL\n",
        "\n",
        "    FIREBASE_DB_URL = db_url\n",
        "\n",
        "    if not firebase_admin._apps:\n",
        "        cred = credentials.Certificate(FIREBASE_SERVICE_ACCOUNT)\n",
        "        FIREBASE_APP = firebase_admin.initialize_app(\n",
        "            cred,\n",
        "            {\"databaseURL\": db_url}\n",
        "        )\n",
        "    else:\n",
        "        FIREBASE_APP = firebase_admin.get_app()\n",
        "\n",
        "    return True\n",
        "\n",
        "\n",
        "def fb_set(path: str, value):\n",
        "    ref = firebase_db.reference(path)\n",
        "    ref.set(value)\n",
        "\n",
        "def fb_push(path: str, value):\n",
        "    ref = firebase_db.reference(path)\n",
        "    ref.push(value)\n",
        "\n",
        "def fb_get(path: str):\n",
        "    ref = firebase_db.reference(path)\n",
        "    return ref.get()\n",
        "\n",
        "def save_index_to_firebase(engine: LectureSearchEngine):\n",
        "    if engine is None or not engine.documents:\n",
        "        return \"⚠️ No index to save.\"\n",
        "\n",
        "    index_payload = {}\n",
        "\n",
        "    for term, locs in engine.word_locations.items():\n",
        "        index_payload[term] = {\n",
        "            str(doc_id): int(freq)\n",
        "            for doc_id, freq in locs\n",
        "        }\n",
        "\n",
        "    meta = {\n",
        "        \"createdAt\": datetime.now(pytz.UTC).isoformat(),\n",
        "        \"docCount\": len(engine.documents),\n",
        "        \"termCount\": len(engine.word_locations),\n",
        "    }\n",
        "\n",
        "    fb_set(\"/indexes/lecture_search/latest/meta\", meta)\n",
        "    fb_set(\"/indexes/lecture_search/latest/terms\", index_payload)\n",
        "\n",
        "    return f\"✅ Index saved correctly. terms={meta['termCount']}\"\n",
        "\n",
        "# Load index FROM Firebase\n",
        "\n",
        "def load_index_from_firebase(engine):\n",
        "    print(\"⏳ Checking Firebase for existing search index...\")\n",
        "    try:\n",
        "        terms_data = fb_get(\"/indexes/lecture_search/latest/terms\")\n",
        "\n",
        "        if not isinstance(terms_data, dict) or not terms_data:\n",
        "            print(\"⚠️ No valid index found in Firebase.\")\n",
        "            return False\n",
        "\n",
        "        engine.word_locations.clear()\n",
        "\n",
        "        loaded_terms = 0\n",
        "        loaded_pairs = 0\n",
        "\n",
        "        for term, doc_map in terms_data.items():\n",
        "            if not isinstance(doc_map, dict) or not doc_map:\n",
        "                continue\n",
        "\n",
        "            # ✅ Normalize term so it matches search() lookup\n",
        "            norm_term = engine.stem_word(str(term).strip().lower())\n",
        "\n",
        "            locs = []\n",
        "            for d_id, freq in doc_map.items():\n",
        "                try:\n",
        "                    locs.append((str(d_id), int(freq)))\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "            if not locs:\n",
        "                continue\n",
        "\n",
        "            # Merge (in case multiple raw keys normalize to same stem)\n",
        "            engine.word_locations[norm_term].extend(locs)\n",
        "            loaded_terms += 1\n",
        "            loaded_pairs += len(locs)\n",
        "\n",
        "        # ✅ Sanity checks (prevents \"loads fine but searches always empty\")\n",
        "        if loaded_terms == 0:\n",
        "            print(\"⚠️ Loaded 0 usable terms (bad structure).\")\n",
        "            return False\n",
        "\n",
        "        # Strong check: ensure at least one common term exists\n",
        "        common = engine.stem_word(\"plant\")\n",
        "        if common not in engine.word_locations:\n",
        "            print(\"⚠️ Loaded index but it doesn't contain common term 'plant' -> treating as invalid.\")\n",
        "            return False\n",
        "\n",
        "        print(f\"✅ Loaded {loaded_terms} terms ({loaded_pairs} postings) from Firebase!\")\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error loading index from Firebase: {e}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "\n",
        "def save_iot_df_to_firebase(feed: str, df: pd.DataFrame, max_rows: int = 2000):\n",
        "\n",
        "    if df is None or df.empty:\n",
        "        return f\"⚠️ No data for feed={feed}\"\n",
        "\n",
        "    dfx = df.copy()\n",
        "\n",
        "    dfx[\"created_at\"] = pd.to_datetime(dfx[\"created_at\"], errors=\"coerce\")\n",
        "    dfx = dfx.dropna(subset=[\"created_at\"])\n",
        "\n",
        "    dfx[\"ts_ms\"] = (dfx[\"created_at\"].astype(\"int64\") // 1_000_000).astype(\"int64\")\n",
        "\n",
        "    dfx = dfx.tail(max_rows)\n",
        "\n",
        "    # Read last saved timestamp\n",
        "    meta_path = f\"/iot/raw_meta/{feed}/last_ts_ms\"\n",
        "    last_ts = fb_get(meta_path)\n",
        "\n",
        "    try:\n",
        "        last_ts = int(last_ts) if last_ts is not None else 0\n",
        "    except:\n",
        "        last_ts = 0\n",
        "\n",
        "    # Filter only new rows\n",
        "    new_rows = dfx[dfx[\"ts_ms\"] > last_ts].copy()\n",
        "    if new_rows.empty:\n",
        "        return f\"✅ No new rows to save for {feed} (dedup OK)\"\n",
        "\n",
        "    base_path = f\"/iot/raw/{feed}\"\n",
        "\n",
        "    # Write each row by deterministic key (set overwrites same key, so no duplicates)\n",
        "    max_written_ts = last_ts\n",
        "    for _, row in new_rows.iterrows():\n",
        "        ts = int(row[\"ts_ms\"])\n",
        "        payload = {\n",
        "            \"created_at\": str(row[\"created_at\"]),\n",
        "            \"value\": None if pd.isna(row.get(\"value\")) else float(row[\"value\"]) if str(row.get(\"value\")).replace('.','',1).isdigit() else row.get(\"value\")\n",
        "        }\n",
        "        fb_set(f\"{base_path}/{ts}\", payload)\n",
        "        if ts > max_written_ts:\n",
        "            max_written_ts = ts\n",
        "\n",
        "    # Update meta with latest written timestamp\n",
        "    fb_set(meta_path, int(max_written_ts))\n",
        "\n",
        "    return f\"✅ Saved {len(new_rows)} NEW rows (dedup) to {base_path}\"\n",
        "\n",
        "\n",
        "# --- 8. Big Data (Spark) Analytics on IoT ---\n",
        "\n",
        "def spark_get_session():\n",
        "    global SPARK\n",
        "    if SPARK is not None:\n",
        "        return SPARK\n",
        "    SPARK = SparkSession.builder.appName(\"IoT Big Data Analytics\").getOrCreate()\n",
        "    return SPARK\n",
        "\n",
        "def compute_bigdata_analytics_from_df(feed: str, df: pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Big data analytics for one feed:\n",
        "    - Required: min/max (per tutorial)\n",
        "    - Extra: avg/std + anomaly count (z-score style)\n",
        "    Saves results to Firebase under /iot/analytics/latest/{feed}\n",
        "    \"\"\"\n",
        "    if df is None or df.empty:\n",
        "        return None, f\"⚠️ No data for {feed}\"\n",
        "\n",
        "    # Prepare clean pandas\n",
        "    dfx = df[[\"created_at\", \"value\"]].dropna().copy()\n",
        "    dfx[\"created_at\"] = pd.to_datetime(dfx[\"created_at\"])\n",
        "    dfx[\"value\"] = pd.to_numeric(dfx[\"value\"], errors=\"coerce\").dropna()\n",
        "\n",
        "    if dfx.empty:\n",
        "        return None, f\"⚠️ No numeric data for {feed}\"\n",
        "\n",
        "    spark = spark_get_session()\n",
        "\n",
        "    # Spark DF\n",
        "    sdf = spark.createDataFrame(dfx.assign(created_at=dfx[\"created_at\"].astype(str)).to_dict(orient=\"records\"))\n",
        "\n",
        "    # Spark aggregations\n",
        "    agg_row = sdf.agg(\n",
        "        spark_min(col(\"value\")).alias(\"min\"),\n",
        "        spark_max(col(\"value\")).alias(\"max\"),\n",
        "        spark_avg(col(\"value\")).alias(\"avg\"),\n",
        "        spark_stddev(col(\"value\")).alias(\"stddev\"),\n",
        "    ).collect()[0]\n",
        "\n",
        "    stats = {\n",
        "        \"feed\": feed,\n",
        "        \"count\": int(sdf.count()),\n",
        "        \"min\": float(agg_row[\"min\"]) if agg_row[\"min\"] is not None else None,\n",
        "        \"max\": float(agg_row[\"max\"]) if agg_row[\"max\"] is not None else None,\n",
        "        \"avg\": float(agg_row[\"avg\"]) if agg_row[\"avg\"] is not None else None,\n",
        "        \"stddev\": float(agg_row[\"stddev\"]) if agg_row[\"stddev\"] is not None else None,\n",
        "    }\n",
        "\n",
        "    # MapReduce-style min/max using RDD (conceptual match)\n",
        "    rdd = sdf.select(\"value\").rdd.map(lambda row: float(row[\"value\"]))\n",
        "    mr_min = rdd.reduce(lambda a, b: a if a < b else b)\n",
        "    mr_max = rdd.reduce(lambda a, b: a if a > b else b)\n",
        "    stats[\"mapreduce_min\"] = float(mr_min)\n",
        "    stats[\"mapreduce_max\"] = float(mr_max)\n",
        "\n",
        "    # Simple anomaly count using z-score (if stddev exists and > 0)\n",
        "    if stats[\"stddev\"] and stats[\"stddev\"] > 0:\n",
        "        mean = stats[\"avg\"]\n",
        "        sd = stats[\"stddev\"]\n",
        "        anomalies = dfx[(dfx[\"value\"] - mean).abs() > 3 * sd]\n",
        "        stats[\"anomalyCount_3sigma\"] = int(len(anomalies))\n",
        "    else:\n",
        "        stats[\"anomalyCount_3sigma\"] = 0\n",
        "\n",
        "    stats[\"generatedAt\"] = datetime.now(pytz.UTC).isoformat()\n",
        "\n",
        "    # Save to Firebase\n",
        "    fb_set(f\"/iot/analytics/latest/{feed}\", stats)\n",
        "\n",
        "    return stats, f\"✅ Big data analytics computed & saved for {feed}\"\n",
        "\n",
        "def run_bigdata_pipeline(chk_temp, chk_hum, chk_soil, limit):\n",
        "    feeds = []\n",
        "    if chk_temp: feeds.append(\"temperature\")\n",
        "    if chk_hum: feeds.append(\"humidity\")\n",
        "    if chk_soil: feeds.append(\"soil\")\n",
        "\n",
        "    if not feeds:\n",
        "        return pd.DataFrame([]), None, \"⚠️ Choose at least one feed.\"\n",
        "\n",
        "    all_stats = []\n",
        "    last_fig = None\n",
        "    logs = []\n",
        "\n",
        "    for feed in feeds:\n",
        "        df = fetch_data_as_df(feed, int(limit), save_to_firebase=True)\n",
        "        stats, msg = compute_bigdata_analytics_from_df(feed, df)\n",
        "        logs.append(msg)\n",
        "\n",
        "        if stats:\n",
        "            all_stats.append(stats)\n",
        "\n",
        "        # Plot last selected feed\n",
        "        if df is not None and not df.empty:\n",
        "            last_fig = create_plot(df, f\"{feed} Trend (for analytics)\", \"green\")\n",
        "\n",
        "    return pd.DataFrame(all_stats), last_fig, \"\\n\".join(logs)\n",
        "\n",
        "def load_latest_analytics_from_firebase():\n",
        "    data = fb_get(\"/iot/analytics/latest\")\n",
        "    if not data:\n",
        "        return pd.DataFrame([])\n",
        "\n",
        "    # data is {feed: stats}\n",
        "    rows = []\n",
        "    for feed, stats in data.items():\n",
        "        if isinstance(stats, dict):\n",
        "            rows.append(stats)\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# CHATBOT LOGIC (GenAI) - FIXED to 2.5 Flash\n",
        "# ==========================================\n",
        "\n",
        "def gemini_care_advice(disease_label: str, confidence: float | None = None) -> str:\n",
        "    \"\"\"\n",
        "    Returns 2–3 short, safe care steps for the detected disease.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        client = get_genai_client()\n",
        "        conf_txt = f\"{confidence:.1%}\" if confidence is not None else \"unknown\"\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "You are an agronomy assistant.\n",
        "Disease detection result: \"{disease_label}\" (confidence: {conf_txt}).\n",
        "\n",
        "Give:\n",
        "1) 2–3 short handling steps (bullet points).\n",
        "2) One prevention tip.\n",
        "Keep it practical and non-technical.\n",
        "If the label is unclear, ask the user what plant it is.\n",
        "\"\"\"\n",
        "\n",
        "        resp = client.models.generate_content(\n",
        "            model=\"gemini-2.5-flash\",\n",
        "            contents=prompt.strip()\n",
        "        )\n",
        "        return resp.text.strip()\n",
        "    except Exception as e:\n",
        "        return f\"(Advice Error: {e})\"\n",
        "\n",
        "\n",
        "def chat_with_gemini(message, history):\n",
        "    \"\"\"\n",
        "    Chatbot function for Tab 7 (stateless).\n",
        "    Uses the new google-genai Client API.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        client = get_genai_client()\n",
        "\n",
        "        system_instruction = (\n",
        "            \"You are a helpful AI assistant for a Smart Plant IoT System. \"\n",
        "            \"You help users understand plant health, sensor data (Temperature, Humidity, Soil Moisture), \"\n",
        "            \"and big data analytics. \"\n",
        "            \"Be concise, friendly, and professional.\"\n",
        "            \"system architecture: 1.Image upload for plant disease detection. 2.IoT Data. 3.Big Data Observations. 4.Search Engine Articles. 5.Dashboard with IoT data graphs. 6.Generate PDF report. 7.AI Chatbot.\"\n",
        "        )\n",
        "\n",
        "        # Optional: include last few turns from Gradio history to improve continuity\n",
        "        # history is typically list[tuple(user, bot)]\n",
        "        last_turns = history[-6:] if history else []\n",
        "        transcript = \"\"\n",
        "        for u, b in last_turns:\n",
        "            transcript += f\"User: {u}\\nAssistant: {b}\\n\"\n",
        "\n",
        "        full_prompt = (\n",
        "            f\"{system_instruction}\\n\\n\"\n",
        "            f\"{transcript}\\n\"\n",
        "            f\"User: {message}\\nAssistant:\"\n",
        "        )\n",
        "\n",
        "        response = client.models.generate_content(\n",
        "            model=\"gemini-2.5-flash\",\n",
        "            contents=full_prompt\n",
        "        )\n",
        "        return response.text\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"⚠️ Error interacting with Gemini: {str(e)}\""
      ],
      "metadata": {
        "id": "fhf0Mfi9YfsS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "0d1d69ff397a4abbb93a3cfd945ce8ed",
            "d3d2b0f79cf146989656254b501a8d41",
            "1e6087b0dd014ac5ac82431eadafa37d",
            "2945134b7f1a415e9e4bb88ef57b438e",
            "914787d6a247474087ab731cd08b2dfa",
            "49dd4c7a1ba044568440f352f1849940",
            "6161f5a81d874ce59e678e958f9af091",
            "137cd340708647b499d9b4965a34c2bc",
            "f98c99190edb481c8258a91b80fe06ba",
            "4b579a90e0494037ab1c6f8b2361a20c",
            "ee2f1010c9064255b78dcdcd27c06acc"
          ]
        },
        "outputId": "1f09b6e9-76aa-4ed2-c6bc-549b777621ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/200 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d1d69ff397a4abbb93a3cfd945ce8ed"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# PART 3: MAIN EXECUTION\n",
        "# ==========================================\n",
        "\n",
        "# 🔥 Firebase init (set your DB URL)\n",
        "FIREBASE_DB_URL = \"\"\n",
        "\n",
        "print(\"🔄 Connecting to Firebase Realtime DB...\")\n",
        "try:\n",
        "    firebase_init(FIREBASE_DB_URL)\n",
        "    print(\"✅ Firebase Connected!\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Firebase Error: {e}\")\n",
        "\n",
        "\n",
        "# --- Load Articles ---\n",
        "ARTICLE_URLS = [\n",
        "    \"https://www.nature.com/articles/s41467-024-50749-4\",\n",
        "    \"https://www.nature.com/articles/s41598-024-72197-2\",\n",
        "    \"https://www.nature.com/articles/s41598-022-15163-0\",\n",
        "    \"https://www.nature.com/articles/srep16564\",\n",
        "    \"https://www.nature.com/articles/s41598-025-15940-7\",\n",
        "]\n",
        "\n",
        "print(\"🌐 Loading articles...\")\n",
        "ARTICLES, DOC_TITLES = load_articles_from_web(ARTICLE_URLS)\n",
        "print(f\"✅ Articles loaded: {len(ARTICLES)}\")\n",
        "\n",
        "engine = LectureSearchEngine()\n",
        "\n",
        "\n",
        "# Try to load from Firebase first, else build\n",
        "index_loaded = load_index_from_firebase(engine)\n",
        "\n",
        "engine.documents = ARTICLES\n",
        "engine.titles = DOC_TITLES\n",
        "\n",
        "if not index_loaded and ARTICLES:\n",
        "    # If not in Firebase, BUILD IT from scratch\n",
        "    print(\"📚 Building Search Index locally...\")\n",
        "    engine.build_index(ARTICLES, DOC_TITLES)\n",
        "\n",
        "    # Save newly built index to Firebase\n",
        "    try:\n",
        "        msg = save_index_to_firebase(engine)\n",
        "        print(msg)\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed saving index to Firebase: {e}\")\n",
        "elif index_loaded:\n",
        "    # Use the loaded index, just ensure it has access to document text for context\n",
        "    engine.documents = ARTICLES\n",
        "    engine.titles = DOC_TITLES\n",
        "    print(\"⏩ Skipped build. Using Cloud Index.\")\n",
        "\n",
        "\n",
        "# 2. Setup AI Models\n",
        "ACTIVE_MODEL = get_working_model()\n",
        "print(\"🤖 Text AI ready (google.genai client, model set per request)\")\n",
        "print(\"🧠 Vision model will load only when you click 'Analyze Leaf' in Tab 1.\")\n",
        "\n",
        "# 3. Launch Gradio UI\n",
        "print(\"\\n🚀 Launching System...\")\n",
        "\n",
        "theme = gr.themes.Soft(\n",
        "    primary_hue=\"green\",\n",
        "    secondary_hue=\"emerald\",\n",
        ").set(\n",
        "    body_background_fill=\"#f3f4f6\",\n",
        "    background_fill_primary=\"#f3f4f6\"\n",
        ")\n",
        "\n",
        "\n",
        "with gr.Blocks(theme=theme, title=\"Smart Plant System\") as demo:\n",
        "\n",
        "    # Header Section\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=5):\n",
        "            gr.Markdown(\"# 🌱 Smart Plant System Ultimate\")\n",
        "        with gr.Column(scale=1):\n",
        "            mode_btn = gr.Button(\"🌗 Light/Dark Mode\", variant=\"secondary\")\n",
        "            mode_btn.click(None, None, None, js=\"() => document.body.classList.toggle('dark')\")\n",
        "\n",
        "    with gr.Tabs():\n",
        "\n",
        "        # Tab 1: Image AI\n",
        "        with gr.TabItem(\"1. Image (AI) 📸\"):\n",
        "            gr.Markdown(\"### 🍃 Plant Disease Detection\")\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    img_input = gr.Image(height=300, label=\"Upload Leaf Photo 📷\", type=\"numpy\")\n",
        "                    analyze_btn = gr.Button(\"🔍 Analyze Leaf\", variant=\"primary\")\n",
        "                with gr.Column():\n",
        "                    img_out = gr.Textbox(label=\"AI Diagnosis 🤖\", lines=4, placeholder=\"Waiting for image...\")\n",
        "            analyze_btn.click(analyze_image, inputs=img_input, outputs=img_out)\n",
        "\n",
        "\n",
        "        # Tab 2: IoT Data & Leaderboard\n",
        "        with gr.TabItem(\"2. IoT Data 📊\"):\n",
        "            gr.Markdown(\"### 📡 Sensor Real-Time Value\")\n",
        "\n",
        "            # 1. IoT Values Row\n",
        "            with gr.Row():\n",
        "                v1 = gr.Textbox(label=\"Current Temperature 🌡️\", lines=1)\n",
        "                v2 = gr.Textbox(label=\"Current Humidity 💧\", lines=1)\n",
        "                v3 = gr.Textbox(label=\"Current Soil Moisture 🌿\", lines=1)\n",
        "\n",
        "            # Last Updated Label (Visual Proof)\n",
        "            lbl_update = gr.Markdown(\"⏳ Waiting for update...\", elem_id=\"update_lbl\")\n",
        "\n",
        "            gr.Markdown(\"---\")\n",
        "\n",
        "            # --- LEADERBOARD & WATERING SECTION ---\n",
        "            with gr.Row():\n",
        "                # Left Side: Controls\n",
        "                with gr.Column(scale=1):\n",
        "                    gr.Markdown(\"### 🎮 Remote Actions\")\n",
        "                    # Water Button\n",
        "                    btn_water = gr.Button(\"🚿 Remote Water (+5 pts) 💧\", variant=\"primary\", size=\"lg\")\n",
        "\n",
        "                    gr.Markdown(\"### ⚙️ Settings\")\n",
        "                    lim = gr.Number(value=20, label=\"Data Limit 🔢\")\n",
        "                    btn_json = gr.Button(\"💾 Export as JSON\", variant=\"secondary\")\n",
        "                    f_out = gr.File(height=50, label=\"Download JSON\", visible=False)\n",
        "\n",
        "                # Right Side: Leaderboard\n",
        "                with gr.Column(scale=2):\n",
        "                    gr.Markdown(\"### 🏆 Top Gardeners (Leaderboard)\")\n",
        "                    leaderboard_table = gr.Dataframe(\n",
        "                        value=get_leaderboard_df,\n",
        "                        headers=[\"Rank\", \"Player\", \"Score\"],\n",
        "                        interactive=False,\n",
        "                        row_count=6\n",
        "                    )\n",
        "\n",
        "            # --- LOGIC ---\n",
        "            # Timer ticks - updates values + timestamp (PARALLEL FETCH)\n",
        "            timer = gr.Timer(5)\n",
        "            # Note: We now output to 4 components (3 values + 1 label)\n",
        "            timer.tick(fetch_sensor_values, inputs=[lim], outputs=[v1, v2, v3, lbl_update])\n",
        "\n",
        "            # Export JSON (Uses full limit)\n",
        "            btn_json.click(export_json_data, inputs=[lim], outputs=[f_out])\n",
        "\n",
        "            # Watering Logic\n",
        "            btn_water.click(update_leaderboard, inputs=None, outputs=leaderboard_table)\n",
        "\n",
        "          # Tab: Big Data Observations\n",
        "        with gr.TabItem(\"3. Big Data Observations 📈\"):\n",
        "            gr.Markdown(\n",
        "                \"### 🧠 Big Data Analytics on IoT Streams\\n\"\n",
        "                \"- Computes **min/max** per parameter (MapReduce requirement) + extra insights.\\n\"\n",
        "                \"- Saves results to Firebase.\\n\"\n",
        "            )\n",
        "\n",
        "            with gr.Row():\n",
        "                with gr.Column(scale=1):\n",
        "                    bt1 = gr.Checkbox(label=\"Temperature 🌡️\", value=True)\n",
        "                    bt2 = gr.Checkbox(label=\"Humidity 💧\", value=False)\n",
        "                    bt3 = gr.Checkbox(label=\"Soil Moisture 🌿\", value=False)\n",
        "                    blim = gr.Number(value=20, label=\"Analytics Limit 🔢\")\n",
        "                    run_bd_btn = gr.Button(\"🚀 Run Big Data Analytics\", variant=\"primary\")\n",
        "\n",
        "                    refresh_fb_btn = gr.Button(\"🔄 Load Latest Analytics from Firebase\", variant=\"secondary\")\n",
        "\n",
        "                with gr.Column(scale=3):\n",
        "                    bd_table = gr.Dataframe(label=\"Analytics Table (saved to Firebase)\")\n",
        "                    bd_plot = gr.Plot(label=\"Trend Plot\")\n",
        "                    bd_log = gr.Textbox(label=\"Logs / Observations\", lines=6)\n",
        "\n",
        "            run_bd_btn.click(\n",
        "                run_bigdata_pipeline,\n",
        "                inputs=[bt1, bt2, bt3, blim],\n",
        "                outputs=[bd_table, bd_plot, bd_log]\n",
        "            )\n",
        "\n",
        "            refresh_fb_btn.click(\n",
        "                load_latest_analytics_from_firebase,\n",
        "                inputs=[],\n",
        "                outputs=[bd_table]\n",
        "            )\n",
        "\n",
        "\n",
        "        # Tab 3: Search Docs\n",
        "        with gr.TabItem(\"4. Search Docs 🔍\"):\n",
        "            gr.Markdown(\"### 📚 Knowledge Base Search\")\n",
        "            with gr.Row():\n",
        "                txt_in = gr.Textbox(label=\"Ask a Question\", placeholder=\"How does photosynthesis work?...\", scale=4)\n",
        "                search_btn = gr.Button(\"🔎 Search\", variant=\"primary\", scale=1)\n",
        "\n",
        "            res_out = gr.Textbox(label=\"AI & Doc Results 💡\", lines=12)\n",
        "            search_btn.click(search_engine_rag, inputs=txt_in, outputs=res_out)\n",
        "\n",
        "        # Tab 4: Dashboard\n",
        "        with gr.TabItem(\"5. Dashboard 🎛️\"):\n",
        "            gr.Markdown(\"### ⚡ Live Monitor\")\n",
        "            dash_btn = gr.Button(\"🔄 Sync Live Data\", variant=\"primary\")\n",
        "\n",
        "            with gr.Row():\n",
        "                b1 = gr.Textbox(label=\"Temp 🌡️\")\n",
        "                b2 = gr.Textbox(label=\"Humidity 💧\")\n",
        "                b3 = gr.Textbox(label=\"Soil 🌿\")\n",
        "                b4 = gr.Textbox(label=\"Status 🚦\")\n",
        "\n",
        "            with gr.Row():\n",
        "                dp1 = gr.Plot(label=\"Temp\")\n",
        "                dp2 = gr.Plot(label=\"Humidity\")\n",
        "            with gr.Row():\n",
        "                dp3 = gr.Plot(label=\"Soil\")\n",
        "\n",
        "            dash_btn.click(refresh_dashboard_real, outputs=[dp1, dp2, dp3, b1, b2, b3, b4])\n",
        "\n",
        "        # Tab 5: Report (UPDATED: Big Data PDF)\n",
        "        with gr.TabItem(\"6. PDF Report 📑\"):\n",
        "            gr.Markdown(\"### 📄 Generate Professional Analytics Report\")\n",
        "            gr.Markdown(\"Generates a PDF based on the latest **Firebase Analytics** (Big Data Stats) instead of raw cache.\")\n",
        "            report_btn = gr.Button(\"🖨️ Generate PDF (Big Data)\", variant=\"primary\")\n",
        "            with gr.Row():\n",
        "                pdf_file = gr.File(label=\"Download PDF 📥\")\n",
        "                report_log = gr.Textbox(label=\"Log 📝\", lines=2)\n",
        "            report_btn.click(generate_pdf_report, outputs=[pdf_file, report_log])\n",
        "\n",
        "        # NEW TAB: Chatbot\n",
        "        with gr.TabItem(\"7. AI Chatbot 💬\"):\n",
        "            gr.Markdown(\"### 🤖 Chat with Plant System AI\")\n",
        "            gr.Markdown(\"Ask anything about the system, gardening, or data!\")\n",
        "\n",
        "            # Using standard Chatbot UI components\n",
        "            chatbot = gr.Chatbot(label=\"Gemini Assistant\", height=400)\n",
        "            msg = gr.Textbox(label=\"Your Message\", placeholder=\"Ask me about the plant system...\")\n",
        "            clear = gr.Button(\"Clear Chat\")\n",
        "\n",
        "            def respond(message, chat_history):\n",
        "                # Call our Gemini helper\n",
        "                bot_message = chat_with_gemini(message, chat_history)\n",
        "                chat_history.append((message, bot_message))\n",
        "                return \"\", chat_history\n",
        "\n",
        "            msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
        "            clear.click(lambda: None, None, chatbot, queue=False)\n",
        "\n",
        "\n",
        "demo.launch(inline=True, height=900, debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ff53c86ef6de4fe395f4591f00bdd937",
            "c1e8b23267ca4af081ef8137551cc3fa",
            "8095200b2363469381988b2203c196e2",
            "288a70c4aa2f4bcc883ba223e236e2b4",
            "172e5a106a6e4767bdc956ed202c145a",
            "6a6eb371642e46bfbc0a7df97cdb1679",
            "c92a3214dbda4840bd2060022cedbfaf",
            "b2cd7f9ffb1f43cfa838e0255b133fde",
            "72742d293f5e44d6b8c605871648db59",
            "29ccea6d3519460eb262751a8c1797f3",
            "7696a19736fd4fe483b17d7d3efbec07",
            "643a0584d56c4ce9862ad4ef0bedab29",
            "88b6c6002a2e489e881eb6709e37cb74",
            "b178156e03ef423d8fe44cd391ff2b05",
            "2e9707c370ae4fc58fb09ac02875d372",
            "d40d0f2c25ff46dabf5c53f63ae5de9c",
            "f98cd30ebcb344ae86ed35cd37d5c48e",
            "602d73344d714f34bdb92481e07fc33c",
            "647c33e5b5ac4e07806dd3b01abcee8e",
            "8ddd87ce63d74a07a62391b826681c62",
            "9463d2c8238e4126aa6b8e2edb644829",
            "198ae85be1a0457c8a8151ed40086d61"
          ]
        },
        "id": "-nHWOjtJYpmd",
        "outputId": "c66c3a23-e804-4074-d3a7-9c70c1773dd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Connecting to Firebase Realtime DB...\n",
            "✅ Firebase Connected!\n",
            "🌐 Loading articles...\n",
            "✅ Loaded [1] Evolution of Phytophthora infestans on its potato host since the Irish potato famine | Nature Communications\n",
            "✅ Loaded [2] Advancing plant leaf disease detection integrating machine learning and deep learning | Scientific Reports\n",
            "✅ Loaded [3] A deep learning based approach for automated plant disease classification using vision transformer | Scientific Reports\n",
            "✅ Loaded [4] Detection of early blight and late blight diseases on tomato leaves using hyperspectral imaging | Scientific Reports\n",
            "✅ Loaded [5] Bayesian optimized CNN ensemble for efficient potato blight detection using fuzzy image enhancement | Scientific Reports\n",
            "✅ Articles loaded: 5\n",
            "⏳ Checking Firebase for existing search index...\n",
            "⚠️ Loaded index but it doesn't contain common term 'plant' -> treating as invalid.\n",
            "📚 Building Search Index locally...\n",
            "✅ Index saved correctly. terms=2480\n",
            "🤖 Text AI ready (google.genai client, model set per request)\n",
            "🧠 Vision model will load only when you click 'Analyze Leaf' in Tab 1.\n",
            "\n",
            "🚀 Launching System...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4111206921.py:73: DeprecationWarning: The 'theme' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'theme' to Blocks.launch() instead.\n",
            "  with gr.Blocks(theme=theme, title=\"Smart Plant System\") as demo:\n",
            "/tmp/ipython-input-4111206921.py:228: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot(label=\"Gemini Assistant\", height=400)\n",
            "/tmp/ipython-input-4111206921.py:228: DeprecationWarning: The default value of 'allow_tags' in gr.Chatbot will be changed from False to True in Gradio 6.0. You will need to explicitly set allow_tags=False if you want to disable tags in your chatbot.\n",
            "  chatbot = gr.Chatbot(label=\"Gemini Assistant\", height=400)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://79198948ec777f324c.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://79198948ec777f324c.gradio.live\" width=\"100%\" height=\"900\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:    Exception in ASGI application\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/protocols/http/httptools_impl.py\", line 416, in run_asgi\n",
            "    result = await app(  # type: ignore[func-returns-value]\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/applications.py\", line 1139, in __call__\n",
            "    await super().__call__(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/applications.py\", line 107, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 186, in __call__\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 164, in __call__\n",
            "    await self.app(scope, receive, _send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/brotli_middleware.py\", line 74, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 882, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/exceptions.py\", line 63, in __call__\n",
            "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 716, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 736, in app\n",
            "    await route.handle(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 290, in handle\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 119, in app\n",
            "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 105, in app\n",
            "    response = await f(request)\n",
            "               ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 385, in app\n",
            "    raw_response = await run_endpoint_function(\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 284, in run_endpoint_function\n",
            "    return await dependant.call(**values)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/routes.py\", line 1671, in get_upload_progress\n",
            "    await asyncio.wait_for(\n",
            "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 528, in is_tracked\n",
            "    return await self._signals[upload_id].wait()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/locks.py\", line 209, in wait\n",
            "    fut = self._get_loop().create_future()\n",
            "          ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/mixins.py\", line 20, in _get_loop\n",
            "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
            "RuntimeError: <asyncio.locks.Event object at 0x7a148bb13f50 [unset]> is bound to a different event loop\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/200 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff53c86ef6de4fe395f4591f00bdd937"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:    Exception in ASGI application\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/protocols/http/httptools_impl.py\", line 416, in run_asgi\n",
            "    result = await app(  # type: ignore[func-returns-value]\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/applications.py\", line 1139, in __call__\n",
            "    await super().__call__(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/applications.py\", line 107, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 186, in __call__\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 164, in __call__\n",
            "    await self.app(scope, receive, _send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/brotli_middleware.py\", line 74, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 882, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/exceptions.py\", line 63, in __call__\n",
            "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 716, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 736, in app\n",
            "    await route.handle(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 290, in handle\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 119, in app\n",
            "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 105, in app\n",
            "    response = await f(request)\n",
            "               ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 385, in app\n",
            "    raw_response = await run_endpoint_function(\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 284, in run_endpoint_function\n",
            "    return await dependant.call(**values)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/routes.py\", line 1671, in get_upload_progress\n",
            "    await asyncio.wait_for(\n",
            "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 528, in is_tracked\n",
            "    return await self._signals[upload_id].wait()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/locks.py\", line 209, in wait\n",
            "    fut = self._get_loop().create_future()\n",
            "          ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/mixins.py\", line 20, in _get_loop\n",
            "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
            "RuntimeError: <asyncio.locks.Event object at 0x7a148bb13f50 [unset]> is bound to a different event loop\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/200 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "643a0584d56c4ce9862ad4ef0bedab29"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1356661725.py:272: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
            "  fig, ax = plt.subplots(figsize=(8, 3.5))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for soil (dedup OK)\n",
            "✅ No new rows to save for humidity (dedup OK)\n",
            "✅ No new rows to save for temperature (dedup OK)\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://79198948ec777f324c.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "print(transformers.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9LW0RCNvvlC",
        "outputId": "49e365a4-7e70-45f3-859f-ef5ea3b0ce79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.0.0\n"
          ]
        }
      ]
    }
  ]
}